{ "publications":[ 
 { 
 "title": "Bitcoin: A Peer-to-Peer Electronic Cash System", 
 "subTitle": "Satoshi Nakamoto, 2008", 
 "published": "Source: https://bitcoin.org/bitcoin.pdf (2008)", 
 "text": "<h2>Bitcoin: A Peer-to-Peer Electronic Cash System</h2> 
 <p>Satoshi Nakamoto<br /> 
 satoshin@gmx.com<br /> 
 www.bitcoin.org</p> 
 <p><strong>Abstract.</strong> A purely peer-to-peer version of electronic cash would allow online payments to be sent directly from one party to another without going through a financial institution. Digital signatures provide part of the solution, but the main benefits are lost if a trusted third party is still required to prevent double-spending. We propose a solution to the double-spending problem using a peer-to-peer network. The network timestamps transactions by hashing them into an ongoing chain of hash-based proof-of-work, forming a record that cannot be changed without redoing the proof-of-work. The longest chain not only serves as proof of the sequence of events witnessed, but proof that it came from the largest pool of CPU power. As long as a majority of CPU power is controlled by nodes that are not cooperating to attack the network, they'll generate the longest chain and outpace attackers. The network itself requires minimal structure. Messages are broadcast on a best effort basis, and nodes can leave and rejoin the network at will, accepting the longest proof-of-work chain as proof of what happened while they were gone.</p> 
  
<h3>1. Introduction</h3> 
 <p>Commerce on the Internet has come to rely almost exclusively on financial institutions serving as trusted third parties to process electronic payments. While the system works well enough for most transactions, it still suffers from the inherent weaknesses of the trust based model. Completely non-reversible transactions are not really possible, since financial institutions cannot avoid mediating disputes. The cost of mediation increases transaction costs, limiting the minimum practical transaction size and cutting off the possibility for small casual transactions, and there is a broader cost in the loss of ability to make non-reversible payments for non-reversible services. With the possibility of reversal, the need for trust spreads. Merchants must be wary of their customers, hassling them for more information than they would otherwise need. A certain percentage of fraud is accepted as unavoidable. These costs and payment uncertainties can be avoided in person by using physical currency, but no mechanism exists to make payments over a communications channel without a trusted party.</p> 
 <p>What is needed is an electronic payment system based on cryptographic proof instead of trust, allowing any two willing parties to transact directly with each other without the need for a trusted third party. Transactions that are computationally impractical to reverse would protect sellers from fraud, and routine escrow mechanisms could easily be implemented to protect buyers. In this paper, we propose a solution to the double-spending problem using a peer-to-peer distributed timestamp server to generate computational proof of the chronological order of transactions. The system is secure as long as honest nodes collectively control more CPU power than any cooperating group of attacker nodes.</p> 
  
<h3>2. Transactions</h3> 
 <p>We define an electronic coin as a chain of digital signatures. Each owner transfers the coin to the next by digitally signing a hash of the previous transaction and the public key of the next owner and adding these to the end of the coin. A payee can verify the signatures to verify the chain of ownership.</p> 
 <p><img width='500' src='bitcoin_transactions.png'></p> 
 <p>The problem of course is the payee can't verify that one of the owners did not double-spend the coin. A common solution is to introduce a trusted central authority, or mint, that checks every transaction for double spending. After each transaction, the coin must be returned to the mint to issue a new coin, and only coins issued directly from the mint are trusted not to be double-spent. The problem with this solution is that the fate of the entire money system depends on the company running the mint, with every transaction having to go through them, just like a bank.</p> 
 <p>We need a way for the payee to know that the previous owners did not sign any earlier transactions. For our purposes, the earliest transaction is the one that counts, so we don't care about later attempts to double-spend. The only way to confirm the absence of a transaction is to be aware of all transactions. In the mint based model, the mint was aware of all transactions and decided which arrived first. To accomplish this without a trusted party, transactions must be publicly announced [1], and we need a system for participants to agree on a single history of the order in which they were received. The payee needs proof that at the time of each transaction, the majority of nodes agreed it was the first received.</p> 
  
<h3>3. Timestamp Server</h3> 
 <p>The solution we propose begins with a timestamp server. A timestamp server works by taking a hash of a block of items to be timestamped and widely publishing the hash, such as in a newspaper or Usenet post [2-5]. The timestamp proves that the data must have existed at the time, obviously, in order to get into the hash. Each timestamp includes the previous timestamp in its hash, forming a chain, with each additional timestamp reinforcing the ones before it.</p> 
 <p><img width='500' src='bitcoin_timestamp-server.png'></p> 
  
<h3>4. Proof-of-Work</h3> 
 <p>To implement a distributed timestamp server on a peer-to-peer basis, we will need to use a proof-of-work system similar to Adam Back's Hashcash [6], rather than newspaper or Usenet posts. The proof-of-work involves scanning for a value that when hashed, such as with SHA-256, the hash begins with a number of zero bits. The average work required is exponential in the number of zero bits required and can be verified by executing a single hash.</p> 
 <p>For our timestamp network, we implement the proof-of-work by incrementing a nonce in the block until a value is found that gives the block's hash the required zero bits. Once the CPU effort has been expended to make it satisfy the proof-of-work, the block cannot be changed without redoing the work. As later blocks are chained after it, the work to change the block would include redoing all the blocks after it.</p> 
 <p><img width='500' src='bitcoin_proof-of-work.png'></p> 
 <p>The proof-of-work also solves the problem of determining representation in majority decision making. If the majority were based on one-IP-address-one-vote, it could be subverted by anyone able to allocate many IPs. Proof-of-work is essentially one-CPU-one-vote. The majority decision is represented by the longest chain, which has the greatest proof-of-work effort invested in it. If a majority of CPU power is controlled by honest nodes, the honest chain will grow the fastest and outpace any competing chains. To modify a past block, an attacker would have to redo the proof-of-work of the block and all blocks after it and then catch up with and surpass the work of the honest nodes. We will show later that the probability of a slower attacker catching up diminishes exponentially as subsequent blocks are added.</p> 
 <p>To compensate for increasing hardware speed and varying interest in running nodes over time, the proof-of-work difficulty is determined by a moving average targeting an average number of blocks per hour. If they're generated too fast, the difficulty increases.</p> 
  
<h3>5. Network</h3> 
 <p>The steps to run the network are as follows:</p> 
 <ol> 
 <li>New transactions are broadcast to all nodes.</li> 
 <li>Each node collects new transactions into a block.</li> 
 <li>Each node works on finding a difficult proof-of-work for its block.</li> 
 <li>When a node finds a proof-of-work, it broadcasts the block to all nodes.</li> 
 <li>Nodes accept the block only if all transactions in it are valid and not already spent.</li> 
 <li>Nodes express their acceptance of the block by working on creating the next block in the chain, using the hash of the accepted block as the previous hash.</li> 
 </ol> 
 <p>Nodes always consider the longest chain to be the correct one and will keep working on extending it. If two nodes broadcast different versions of the next block simultaneously, some nodes may receive one or the other first. In that case, they work on the first one they received, but save the other branch in case it becomes longer. The tie will be broken when the next proof- of-work is found and one branch becomes longer; the nodes that were working on the other branch will then switch to the longer one.</p> 
 <p>New transaction broadcasts do not necessarily need to reach all nodes. As long as they reach many nodes, they will get into a block before long. Block broadcasts are also tolerant of dropped messages. If a node does not receive a block, it will request it when it receives the next block and realizes it missed one.</p> 
  
<h3>6. Incentive</h3> 
 <p>By convention, the first transaction in a block is a special transaction that starts a new coin owned by the creator of the block. This adds an incentive for nodes to support the network, and provides a way to initially distribute coins into circulation, since there is no central authority to issue them. The steady addition of a constant of amount of new coins is analogous to gold miners expending resources to add gold to circulation. In our case, it is CPU time and electricity that is expended.</p> 
 <p>The incentive can also be funded with transaction fees. If the output value of a transaction is less than its input value, the difference is a transaction fee that is added to the incentive value of the block containing the transaction. Once a predetermined number of coins have entered circulation, the incentive can transition entirely to transaction fees and be completely inflation free.</p> 
 <p>The incentive may help encourage nodes to stay honest. If a greedy attacker is able to assemble more CPU power than all the honest nodes, he would have to choose between using it to defraud people by stealing back his payments, or using it to generate new coins. He ought to find it more profitable to play by the rules, such rules that favour him with more new coins than everyone else combined, than to undermine the system and the validity of his own wealth.</p> 
  
<h3>7. Reclaiming Disk Space</h3> 
 <p>Once the latest transaction in a coin is buried under enough blocks, the spent transactions before it can be discarded to save disk space. To facilitate this without breaking the block's hash, transactions are hashed in a Merkle Tree [7][2][5], with only the root included in the block's hash. Old blocks can then be compacted by stubbing off branches of the tree. The interior hashes do not need to be stored.</p> 
 <p><img width='600' src='bitcoin_reclaiming-disk-space.png'></p> 
 <p>A block header with no transactions would be about 80 bytes. If we suppose blocks are generated every 10 minutes, 80 bytes * 6 * 24 * 365 = 4.2MB per year. With computer systems typically selling with 2GB of RAM as of 2008, and Moore's Law predicting current growth of 1.2GB per year, storage should not be a problem even if the block headers must be kept in memory.</p> 
  
<h3>8. Simplified Payment Verification</h3> 
 <p>It is possible to verify payments without running a full network node. A user only needs to keep a copy of the block headers of the longest proof-of-work chain, which he can get by querying network nodes until he's convinced he has the longest chain, and obtain the Merkle branch linking the transaction to the block it's timestamped in. He can't check the transaction for himself, but by linking it to a place in the chain, he can see that a network node has accepted it, and blocks added after it further confirm the network has accepted it.</p> 
 <p><img width='600' src='bitcoin_simplified-payment-verification.png'></p> 
 <p>As such, the verification is reliable as long as honest nodes control the network, but is more vulnerable if the network is overpowered by an attacker. While network nodes can verify transactions for themselves, the simplified method can be fooled by an attacker's fabricated transactions for as long as the attacker can continue to overpower the network. One strategy to protect against this would be to accept alerts from network nodes when they detect an invalid block, prompting the user's software to download the full block and alerted transactions to confirm the inconsistency. Businesses that receive frequent payments will probably still want to run their own nodes for more independent security and quicker verification.</p> 
  
<h3>9. Combining and Splitting Value</h3> 
 <p>Although it would be possible to handle coins individually, it would be unwieldy to make a separate transaction for every cent in a transfer. To allow value to be split and combined,transactions contain multiple inputs and outputs. Normally there will be either a single input from a larger previous transaction or multiple inputs combining smaller amounts, and at most two outputs: one for the payment, and one returning the change, if any, back to the sender.</p> 
 <p><img width='275' src='bitcoin_combining-splitting-value.png'></p> 
 <p>It should be noted that fan-out, where a transaction depends on several transactions, and those transactions depend on many more, is not a problem here. There is never the need to extract a complete standalone copy of a transaction's history.</p> 
  
<h3>10. Privacy</h3> 
 <p>The traditional banking model achieves a level of privacy by limiting access to information to the parties involved and the trusted third party. The necessity to announce all transactions publicly precludes this method, but privacy can still be maintained by breaking the flow of information in another place: by keeping public keys anonymous. The public can see that someone is sending an amount to someone else, but without information linking the transaction to anyone. This is similar to the level of information released by stock exchanges, where the time and size of individual trades, the 'tape', is made public, but without telling who the parties were.</p> 
 <p><img width='600' src='bitcoin_privacy.png'></p> 
 <p>As an additional firewall, a new key pair should be used for each transaction to keep them from being linked to a common owner. Some linking is still unavoidable with multi-input transactions, which necessarily reveal that their inputs were owned by the same owner. The risk is that if the owner of a key is revealed, linking could reveal other transactions that belonged to the same owner.</p> 
  
<h3>11. Calculations</h3> 
 <p>We consider the scenario of an attacker trying to generate an alternate chain faster than the honest chain. Even if this is accomplished, it does not throw the system open to arbitrary changes, such as creating value out of thin air or taking money that never belonged to the attacker. Nodes are not going to accept an invalid transaction as payment, and honest nodes will never accept a block containing them. An attacker can only try to change one of his own transactions to take back money he recently spent.</p> 
 <p>The race between the honest chain and an attacker chain can be characterized as a Binomial Random Walk. The success event is the honest chain being extended by one block, increasing its lead by +1, and the failure event is the attacker's chain being extended by one block, reducing the gap by -1.</p> 
 <p>The probability of an attacker catching up from a given deficit is analogous to a Gambler's Ruin problem. Suppose a gambler with unlimited credit starts at a deficit and plays potentially an infinite number of trials to try to reach breakeven. We can calculate the probability he ever reaches breakeven, or that an attacker ever catches up with the honest chain, as follows [8]:</p> 
 <div style='margin-left: 20px'> 
 <i>p</i> = probability an honest node finds the next block<br> 
 <i>q</i> = probability the attacker finds the next block<br> 
 <i>q<sub>z</sub></i> = probability the attacker will ever catch up from <i>z</i> blocks behind</p> 
 <p><img src='bitcoin_eq1.png' height='60' alt='eq1.img'> 
 </div> 
 <p>Given our assumption that <i>p &gt; q</i>, the probability drops exponentially as the number of blocks the attacker has to catch up with increases. With the odds against him, if he doesn't make a lucky lunge forward early on, his chances become vanishingly small as he falls further behind.</p> 
 <p>We now consider how long the recipient of a new transaction needs to wait before being sufficiently certain the sender can't change the transaction. We assume the sender is an attacker who wants to make the recipient believe he paid him for a while, then switch it to pay back to himself after some time has passed. The receiver will be alerted when that happens, but the sender hopes it will be too late.</p> 
 <p>The receiver generates a new key pair and gives the public key to the sender shortly before signing. This prevents the sender from preparing a chain of blocks ahead of time by working on it continuously until he is lucky enough to get far enough ahead, then executing the transaction at that moment. Once the transaction is sent, the dishonest sender starts working in secret on a parallel chain containing an alternate version of his transaction.</p> 
 <p>The recipient waits until the transaction has been added to a block and <i>z</i> blocks have been linked after it. He doesn't know the exact amount of progress the attacker has made, but assuming the honest blocks took the average expected time per block, the attacker's potential progress will be a Poisson distribution with expected value:</p> 
 <div style='margin-left: 20px'> 
 <p><img src='bitcoin_eq2.png' height='40' alt='eq2.img''></p> 
 </div> 
 <p>To get the probability the attacker could still catch up now, we multiply the Poisson density for each amount of progress he could have made by the probability he could catch up from that point:</p> 
 <div style='margin-left: 20px'> 
 <p><img src='bitcoin_eq3.png' height='65' alt='eq3.img'></p> 
 </div> 
 <p>Rearranging to avoid summing the infinite tail of the distribution...</p> 
 <div style='margin-left: 20px'> 
 <p><img src='bitcoin_eq4.png' height='60' alt='eq4.img''></p> 
 </div> 
 <p>Converting to C code...</p> 
 <pre> 
 #include <math.h><br> 
 double AttackerSuccessProbability(double q, int z)<br> 
 {<br> 
 double p = 1.0 - q;<br> 
 double lambda = z * (q / p);<br> 
 double sum = 1.0;<br> 
 int i, k;<br> 
 for (k = 0; k <= z; k++)<br> 
 {<br> 
 double poisson = exp(-lambda);<br> 
 for (i = 1; i <= k; i++)<br> 
 poisson *= lambda / i;<br> 
 sum -= poisson * (1 - pow(q / p, z - k));<br> 
 }<br> 
 return sum;<br> 
 }<br> 
 </pre> 
 <p>Running some results, we can see the probability drop off exponentially with <i>z</i>.</p> 
 <pre> 
 q=0.1<br> 
 z=0 P=1.0000000<br> 
 z=1 P=0.2045873<br> 
 z=2 P=0.0509779<br> 
 z=3 P=0.0131722<br> 
 z=4 P=0.0034552<br> 
 z=5 P=0.0009137<br> 
 z=6 P=0.0002428<br> 
 z=7 P=0.0000647<br> 
 z=8 P=0.0000173<br> 
 z=9 P=0.0000046<br> 
 z=10 P=0.0000012<br> 
<br> 
 q=0.3<br> 
 z=0 P=1.0000000<br> 
 z=5 P=0.1773523<br> 
 z=10 P=0.0416605<br> 
 z=15 P=0.0101008<br> 
 z=20 P=0.0024804<br> 
 z=25 P=0.0006132<br> 
 z=30 P=0.0001522<br> 
 z=35 P=0.0000379<br> 
 z=40 P=0.0000095<br> 
 z=45 P=0.0000024<br> 
 z=50 P=0.0000006<br> 
 </pre> 
 <p>Solving for P less than 0.1%...</p> 
 <pre> 
 P < 0.001<br> 
 q=0.10 z=5<br> 
 q=0.15 z=8<br> 
 q=0.20 z=11<br> 
 q=0.25 z=15<br> 
 q=0.30 z=24<br> 
 q=0.35 z=41<br> 
 q=0.40 z=89<br> 
 q=0.45 z=340<br> 
 </pre> 
  
<h3>12. Conclusion</h3> 
 <p>We have proposed a system for electronic transactions without relying on trust. We started with the usual framework of coins made from digital signatures, which provides strong control of ownership, but is incomplete without a way to prevent double-spending. To solve this, we proposed a peer-to-peer network using proof-of-work to record a public history of transactions that quickly becomes computationally impractical for an attacker to change if honest nodes control a majority of CPU power. The network is robust in its unstructured simplicity. Nodes work all at once with little coordination. They do not need to be identified, since messages are not routed to any particular place and only need to be delivered on a best effort basis. Nodes can leave and rejoin the network at will, accepting the proof-of-work chain as proof of what happened while they were gone. They vote with their CPU power, expressing their acceptance of valid blocks by working on extending them and rejecting invalid blocks by refusing to work on them. Any needed rules and incentives can be enforced with this consensus mechanism.</p> 
  
<a name='xxx'></a>
<h3>References</h3>
 <ol> 
 <li><p>W. Dai, 'b-money', 1998</p></li> 
 <li><p>H. Massias, X.S. Avila, and J.-J. Quisquater, 'Design of a secure timestamping service with minimal trust requirements,' In <em>20th Symposium on Information Theory in the Benelux</em>, May 1999.&nbsp;</p></li> 
 <li><p>S. Haber, W.S. Stornetta, 'How to time-stamp a digital document,' In <em>Journal of Cryptology</em>, vol 3, no 2, pages 99-111, 1991.</p></li> 
 <li><p>D. Bayer, S. Haber, W.S. Stornetta, 'Improving the efficiency and reliability of digital time-stamping,' In <em>Sequences II: Methods in Communication, Security and Computer Science</em>, pages 329-334, 1993.</p></li> 
 <li><p>S. Haber, W.S. Stornetta, 'Secure names for bit-strings,' In <em>Proceedings of the 4th ACM Conference on Computer and COmmunications Security</em>, pages 28-35, April 1997.</p></li> 
 <li><p>A. Back, 'Hashcash - a denial of service counter-measure,', 2002.</p></li> 
 <li><p>R.C. Merkle, 'Protocols for public key cryptosystems,' In <em>Proc. 1980 Symposium on Security and Privacy</em>, IEEE Computer Society, pages 122-133, April 1980.</p></li> 
 <li><p>W. Feller, 'An introduction to probability theory and its applications,' 1957.</p></li> 
 </ol>" 
 }, 
 { 
 "title": "b-money", 
 "subTitle": "W. Dai, 1998", 
 "published": "source: http://www.weidai.com/bmoney.txt (1998)", 
 "text": "I am fascinated by Tim May's crypto-anarchy. Unlike the communities 
traditionally associated with the word 'anarchy', in a crypto-anarchy the 
government is not temporarily destroyed but permanently forbidden and 
permanently unnecessary. It's a community where the threat of violence is 
impotent because violence is impossible, and violence is impossible 
because its participants cannot be linked to their true names or physical 
locations. 
<br><br> 
Until now it's not clear, even theoretically, how such a community could 
operate. A community is defined by the cooperation of its participants, 
and efficient cooperation requires a medium of exchange (money) and a way 
to enforce contracts. Traditionally these services have been provided by 
the government or government sponsored institutions and only to legal 
entities. In this article I describe a protocol by which these services 
can be provided to and by untraceable entities. 
<br><br> 
I will actually describe two protocols. The first one is impractical, 
because it makes heavy use of a synchronous and unjammable anonymous 
broadcast channel. However it will motivate the second, more practical 
protocol. In both cases I will assume the existence of an untraceable 
network, where senders and receivers are identified only by digital 
pseudonyms (i.e. public keys) and every messages is signed by its sender 
and encrypted to its receiver. 
<br><br> 
In the first protocol, every participant maintains a (seperate) database 
of how much money belongs to each pseudonym. These accounts collectively 
define the ownership of money, and how these accounts are updated is the 
subject of this protocol. 
<br><br> 
1. The creation of money. Anyone can create money by broadcasting the 
solution to a previously unsolved computational problem. The only 
conditions are that it must be easy to determine how much computing effort 
it took to solve the problem and the solution must otherwise have no 
value, either practical or intellectual. The number of monetary units 
created is equal to the cost of the computing effort in terms of a 
standard basket of commodities. For example if a problem takes 100 hours 
to solve on the computer that solves it most economically, and it takes 3 
standard baskets to purchase 100 hours of computing time on that computer 
on the open market, then upon the broadcast of the solution to that 
problem everyone credits the broadcaster's account by 3 units. 
<br><br> 
2. The transfer of money. If Alice (owner of pseudonym K_A) wishes to 
transfer X units of money to Bob (owner of pseudonym K_B), she broadcasts 
the message 'I give X units of money to K_B' signed by K_A. Upon the 
broadcast of this message, everyone debits K_A's account by X units and 
credits K_B's account by X units, unless this would create a negative 
balance in K_A's account in which case the message is ignored. 
<br><br> 
3. The effecting of contracts. A valid contract must include a maximum 
reparation in case of default for each participant party to it. It should 
also include a party who will perform arbitration should there be a 
dispute. All parties to a contract including the arbitrator must broadcast 
their signatures of it before it becomes effective. Upon the broadcast of 
the contract and all signatures, every participant debits the account of 
each party by the amount of his maximum reparation and credits a special 
account identified by a secure hash of the contract by the sum the maximum 
reparations. The contract becomes effective if the debits succeed for 
every party without producing a negative balance, otherwise the contract 
is ignored and the accounts are rolled back. A sample contract might look 
like this: 
<br><br> 
K_A agrees to send K_B the solution to problem P before 0:0:0 1/1/2000. 
K_B agrees to pay K_A 100 MU (monetary units) before 0:0:0 1/1/2000. K_C 
agrees to perform arbitration in case of dispute. K_A agrees to pay a 
maximum of 1000 MU in case of default. K_B agrees to pay a maximum of 200 
MU in case of default. K_C agrees to pay a maximum of 500 MU in case of 
default. 
<br><br> 
4. The conclusion of contracts. If a contract concludes without dispute, 
each party broadcasts a signed message 'The contract with SHA-1 hash H 
concludes without reparations.' or possibly 'The contract with SHA-1 hash 
H concludes with the following reparations: ...' Upon the broadcast of all 
signatures, every participant credits the account of each party by the 
amount of his maximum reparation, removes the contract account, then 
credits or debits the account of each party according to the reparation 
schedule if there is one. 
<br><br> 
5. The enforcement of contracts. If the parties to a contract cannot agree 
on an appropriate conclusion even with the help of the arbitrator, each 
party broadcasts a suggested reparation/fine schedule and any arguments or 
evidence in his favor. Each participant makes a determination as to the 
actual reparations and/or fines, and modifies his accounts accordingly. 
<br><br> 
In the second protocol, the accounts of who has how much money are kept by 
a subset of the participants (called servers from now on) instead of 
everyone. These servers are linked by a Usenet-style broadcast channel. 
The format of transaction messages broadcasted on this channel remain the 
same as in the first protocol, but the affected participants of each 
transaction should verify that the message has been received and 
successfully processed by a randomly selected subset of the servers. 
<br><br> 
Since the servers must be trusted to a degree, some mechanism is needed to 
keep them honest. Each server is required to deposit a certain amount of 
money in a special account to be used as potential fines or rewards for 
proof of misconduct. Also, each server must periodically publish and 
commit to its current money creation and money ownership databases. Each 
participant should verify that his own account balances are correct and 
that the sum of the account balances is not greater than the total amount 
of money created. This prevents the servers, even in total collusion, from 
permanently and costlessly expanding the money supply. New servers can 
also use the published databases to synchronize with existing servers. 
<br><br> 
The protocol proposed in this article allows untraceable pseudonymous 
entities to cooperate with each other more efficiently, by providing them 
with a medium of exchange and a method of enforcing contracts. The 
protocol can probably be made more efficient and secure, but I hope this 
is a step toward making crypto-anarchy a practical as well as theoretical 
possibility. 
<br><br> 
------- 
<br><br> 
Appendix A: alternative b-money creation 
<br><br> 
One of the more problematic parts in the b-money protocol is money 
creation. This part of the protocol requires that all of the account 
keepers decide and agree on the cost of particular computations. 
Unfortunately because computing technology tends to advance rapidly and 
not always publicly, this information may be unavailable, inaccurate, or 
outdated, all of which would cause serious problems for the protocol. 
<br><br> 
So I propose an alternative money creation subprotocol, in which account 
keepers (everyone in the first protocol, or the servers in the second 
protocol) instead decide and agree on the amount of b-money to be created 
each period, with the cost of creating that money determined by an 
auction. Each money creation period is divided up into four phases, as 
follows: 
<br><br> 
1. Planning. The account keepers compute and negotiate with each other to 
determine an optimal increase in the money supply for the next period.  
Whether or not the account keepers can reach a consensus, they each 
broadcast their money creation quota and any macroeconomic calculations 
done to support the figures.  
<br><br> 
2. Bidding. Anyone who wants to create b-money broadcasts a bid in the 
form of <x, y> where x is the amount of b-money he wants to create, and y 
is an unsolved problem from a predetermined problem class. Each problem in 
this class should have a nominal cost (in MIPS-years say) which is 
publicly agreed on. 
<br><br> 
3. Computation. After seeing the bids, the ones who placed bids in the 
bidding phase may now solve the problems in their bids and broadcast the 
solutions. 
<br><br> 
4. Money creation. Each account keeper accepts the highest bids (among 
those who actually broadcasted solutions) in terms of nominal cost per 
unit of b-money created and credits the bidders' accounts accordingly. 
" 
 }, 
 { 
 "title": "Design of a Secure Timestamping Service with Minimal Trust Requirement", 
 "subTitle": "H. Massias, X.S. Avila, and J.-J. Quisquater, 1999", 
 "published": "Published in: 20th Symposium on Information Theory in the Benelux, 1999", 
 "text": " 
<center> 
<div style='margin:30 0 0 0'> 
<h2>DESIGN OF A SECURE TIMESTAMPING SERVICE WITH MINIMAL TRUST REQUIREMENT</h2> 
</div> 
H. Massias, X. Serret Avila, J.-J. Quisquater<br> 
UCL Crypto group<br> 
Place du Levant. 3. B-1348 Louvain-la-Neuve, Belgium<br> 
<font face= 'Courier New'>massias, serret, jjq@dice.ucl.ac.be</font> 
</center> 
<div style='line-height: 1.5'> 
<br><br> 
 <p><strong>Abstract.</strong> This paper presents our design of a timestamping system for the Belgian project TIMESEC. We first introduce the timestamping method used and we justify our choice for it. Then we present the design of our implementation as well as some of the important issues we found and the solutions we gave to them.</div> 
 
<h3>INTRODUCTION</h3> 
 
The creation date of digital documents and the times expressed in them are becoming increasingly important as digital documents are being introduced into the legal domain. 
We define 'digital timestamp' as a digital certificate intended to assure the existence of a generic digital document at a certain time. 
In order to produce fully trusted timestamps, very specific designs have been introduced. We give an overview of the most relevant methods and we introduce the one we used for the implementation of the Belgian project TIMESEC (see [PRQ<sup>+</sup>98]), justifying our choice for it. Then we present the design of the timestamping system we made for this project. We separate the different processes that are: document timestamping, timestamp verification, auditing, system start-up and system shutdown. 
 
<h3>INTRODUCTION OF THE TIMESTAMPING TECHNIQUES</h3> 
 
There are two families of timestamping techniques: those that work with a trusted third party and those that are based on the concept of distributed trust. Techniques based on a trusted third party rely on the impartiality of the entity that is in charge of issuing the timestamps. Techniques based on the distributed trust consist on making documents dated and signed by a large set of people in order to convince the verifiers that we could not have corrupted all of them. The trusted third party techniques can also be classified into two different kinds: those where the third party is completely trusted and those where it is partially trusted. A detailed study of timestamping techniques can be found in [MQ97]. 
<br> 
We believe that techniques based on distributed trust are not really workable in a professional environment, that is why we concentrate on the trusted third party approach. Nevertheless, we imposed to ourselves the requirement to lower the necessary trust on the third party to the maximum extend. 
<br> 
The 'easy' solution, which consists on concatenating the document with the current time and sign the result, has been discarded because it has two main drawbacks: 
<ol> 
<li>We must completely trust the third party, called Secure Timestamp Authority (STA), which can issue undetectable back-dated timestamps.</li> 
<li>The limited lifetime of cryptographic signatures, which can be shorter than the document time-to-life.</li> 
</ol> 
 
The timestamping method that we have hosen uses a binary tree structure and has been described in [HS91] and [HS97]. This method works by rounds. For each round a binary tree is constructed with the requests filled during it. The rounds have a fixed duration, which is the result of a trade-of between the timestamps accuracy and the number of requests submitted. In Figure 1 we can see a graphical representation of a round constructed using this method.<br> 
<center> 
<br> 
<img src='timestamping_fig1.png' width='450px'> 
<br><br> 
Figure 1: The binary tree structure 
</center> 
<br> 
 
Each of the timestamp requests consists on a hash value of a given document. The leafs of the tree are each of those hash values. The leaf values are then concatenated by two and hashed again to obtain the parent value (Ex: H<sub>43</sub>=H(y<sub>3</sub>|y<sub>4</sub>). The process is repeated for each level until a single value is obtained. Finally, the top value of the round tree (H<sub>18</sub>), called the 'Round Root Value', is then concatenated with the value obtained for the preceding round (RH<sub>i-1</sub>) and then hashed again to obtain the actual 'Round Value' (RH<sub>i</sub>).<br> 
The timestamp of the document contains all the values necessary to rebuilt the corresponding branch of the tree. For example, the timestamp for y<sub>4</sub> contains {(y<sub>3</sub>, L), (H<sub>12</sub>, L), (H<sub>58</sub>, L), (RH<sub>i-1</sub>, L)}. The verification process consists of rebuilding the tree's branch and the linking chain of 'Round Values' until a trusted (from the verifier point of view) 'Round Value' is recomputed. This verification method is explained in detail in [HS91] and [MQ97].<br> 
Periodically, one of the 'Round Values' is published on an unmodifiable, widely witnessed media (Ex: newspaper...). These special 'Round Values', which we will all 'Big Round Values', are the base of the trust for all the timestamps issued. All verifiers must trust these 'Big Round Values' as well as the time associated with them. This is a reasonable requirement because those values are widely witnessed. The absolute time trusted by all the potential verifiers is the time indicated by the unmodifiable media. We suppose that this time is the same than the time indicated by the STA for the 'Big Round'. Forcing the clients to check the timestamps as soon as they get them is another requirement. In that way the process is continuously audited and the STA will not have any margin to maneuver in an untrusted way. 
<br> 
A very useful method for extending the lifetime of timestamps is described in [BHS92]. It basically consists on re-timestamping the hash of the document as well as the original timestamp before the hash function is broken. 
<br> 
We build two trees in parallel for each round using two different hash functions (SHA-1 and RIPEMD-160). In that way, the system remains secure in the case of an unexpected break of one of the hash functions used. 
 
 
<h3>DESCRIPTION AND ANALYSIS OF THE TIMESEC TIMESTAMPING IMPLEMENTATION</h3> 
We will now introduce the basic design of the system we have developed, which is based on the technique introduced above. 
<br> 
Initially, the user designates a document to be timestamped. Two hashes of it are created using the SHA-1 and RIPEMD-160 algorithms. The request containing the two hashes is then sent by the client to the STA. Upon request receipt, the STA creates the corresponding timestamp using the following process. 
 
<h3>Main description of the timestamping process</h3> 
The system design follows a highly de coupled multi-threaded approach. Each step is assigned to a specific component, which has its own different thread. In the Figure 2 we present a schematic outline of the process. The multi-thread approach is justified by the requirement to obtain a highly responsive and load independent implementation. By isolating the process charges into independent steps we try to decouple the load between them. Each step has also a working queue. Those queues are in charge of softening the speed differences between the different process steps. 
 
<center> 
<br> 
<img src='timestamping_fig2.png' width='450px'> 
<br><br> 
Figure 2: Interactions between the components 
</center> 
<br> 
 
The 'Network Listener' is in charge of continuously listen to the clients' timestamp requests. The 'Request Timer' receives the constructed requests from the 'Network Listener'. Then, it times and forwards them to the actual 'Round Queue Coordinator'. Each round has its own 'Round Queue Coordinator', which is in charge of compiling and processing into a tree all the requests belonging to the round. When the round tree has been computed it is forwarded to the 'Timestamp Generator', which generates the corresponding timestamps. Once a timestamp is generated, the 'Timestamp Generator' forwards it to the 'Network Answer', which in turn forwards it to the client. 
 
<h3>The Network Listener</h3> 
 
The 'Network Listener' responsibility is to listen the network continuously for timestamping requests. When it receives a data stream, the 'Network Listener' 
checks it in order to determine if it is a valid request. In the case it is, it sends an affirmative contact response to the client, it creates a 'Timestamp Request' object and adds it to the 'Request Timer' queue. Then it goes back to listen to the network. In the case the request message is not correct, it sends an error message to the client. 
<br> 
We tried to give as few tasks as possible to the 'Network Listener' to let it listen the network, which is its primary task. In order to improve the overall performance, and to avoid the fact that a slow client connection could affect the other ones, several copies of the 'Network Listener' can be active at the same time. 
 
<h3>The Request Timer</h3> 
 
There is only an instance of 'The Request Timer' in the system. The 'Request Timer' is in charge of ordering the requests received from the several 'Network Listeners' and timing them accordingly. All delays introduced by the system before that point (namely, those introduced by the 'Network Listener') are indistinguishable from network delays, and thus not taken into account. Once a request has been timed, the 'Request Timer' tries to add it to the current round queue. As the rounds are closed asynchronously by the corresponding 'Round Queue Coordinator' this operation is not always successful, in that case, the 'Request Timer' re-times the request and retries to queue it until it finds an open round. In that process the request sequence is preserved in order to provide a 
consistent behavior. 
<br> 
<b>Round Queue Coordinator creation:</b> 'Round Queue Coordinator' instances are created by the 'Request Timer' upon processing a request corresponding to a non-existing round. The creation of the rounds that have no requests is delayed until a request is received. Once created, those empty rounds are immediately processed, introducing no significant delay into the process. 
<br> 
<b>Round number determination:</b> Round numbers form a non-interrupted increasing integer sequence. Rounds are always in synchronization with the round duration intervals. In other words, if the round duration is one minute, all rounds will start in an absolute minute boundary, independently from when the system has been started. 'Big Rounds' are determined by the 'Request Timer' using a similar approach to the one followed to determine the round boundaries. We do not restrict the duration of the round to a fixed value for the lifetime of the STA. To achieve this, the information about round and 'Big Round' duration is introduced into the system at the start-up phase. If we wish to modify it, we must first shutdown the system, change the values and then restart the system, which is the only safe procedure we had foreseen.  
 
<h3>The Round Queue Coordinator</h3> 
 
The first thing a 'Round Queue Coordinator' does is to determine the offset between the actual time and the round due time. Requests will be accepted only if the round is still valid (round is open). When requested by the 'Request Timer', the 'Round Queue Coordinator' adds the request to the queue and logs it. This logged request will be latter used for process auditing purposes. 
<br> 
When the round time is over, it obtains the 'Round Values' from the preceding round and it computes the round binary trees (one for each hash algorithm) to obtain the corresponding 'Round Values'. Then it gives the computed trees to the 'Timestamp Generator' and finally adds to the log the 'Round Values' and the 'Round Root Values'. Those logged values will be latter used for timestamp verification and process auditing purposes. If the actual round is a 'Big Round' those values are forwarded to a fixed media as well. 
<br> 
As you may have noticed in the section 'Introduction of the timestamping techniques', the binary tree is defined for a number of leafs (requests) that is a power of 2. In general, this is not the case. We could create fake requests to finish the tree, but this will add a lot of requests (if we have 2<sup>n</sup>+1 requests, then we will need to add 2<sup>n</sup>-1 fake requests). A smarter solution is to add a random value only when we need it. Then, we add at most n values (one for each level of the tree). We call these nodes 'Special Node', which will be logged as well. Instead of random values we could choose to use 0 or another fixed value, this would be as secure as our choice if the hash functions were 'perfect'. As hash functions are only 'presumably perfect', we though that we could made our design more secure with really few additional computations. 
<br> 
In our implementation, the STA queues the requests and computes the tree at the end of the round. At first sight, it could seem a more natural solution to build the tree as soon as the requests arrive. At the end of the round, the computation of the tree would then be ended by getting the last 'Round Value' and computing the actual 'Round Value'. In fact, this solution is harder to implement, and has no effect on the security achieved as no one can check that the STA does not perform any reordering of the requests before it publishes the 'Round Value'. 
  
<h3>The Timestamp Generator</h3> 
 
The 'Timestamp Generator' processes the round trees by pairs (one for each hash algorithm) in order to generate the timestamps for each of the requests contained in the trees. In order to maximize the system responsiveness, once a timestamp has been generated it is immediately forwarded to the 'Network Answer'. Finally, when all the timestamps contained in a round tree have been processed the tree is destroyed. 
 
<h3>The Network Answer</h3> 
 
The 'Network Answer' is in charge of forwarding the processed timestamps to the clients. It has been specified in such a way that it an run several threads, in that way the rest of the timestamping process can be isolated from possible network delay problematic. 
 
<h3>The timestamp verification process</h3> 
First, the verifier designates a document and its corresponding timestamp for verification. Then, the verifier's system (his personal computer or a remote computer independent from the STA) generates the two document hashes and checks if they match with those contained in the timestamp. Afterwards, the 'Round Value' is reconstructed using the data provided in the timestamp. If the computed 'Round Value' is consistent with the one contained in the timestamp then the next step in the verification process is to compare this 'Round Value' to the 'Round Value' obtained from the STA repository. Finally, the verifier provides his system with the two 'Big Round Values' that he founds in the 'unmodifiable media'; the verifier's system gets all the necessary 'Round Values' and 'Root Round Values' from the STA and it checks the coherency of the two linking chains (one for each hash function). 
 
<h3>The audit process</h3> 
The auditor designates two 'Big Rounds', which he fetches from a fixed media. The system behavior will be checked between these two 'Big Round Values'. For each round, the auditor's system gets all the hash values (leafs of the tree and 'Special Nodes') and the 'Round Value' from the STA. Then, it constructs the two trees and checks that the 'Round Value' is consistent. These two steps are repeated until all the considered rounds are checked or until an error has been found. In that way, all theoretically verifiable system behavior can be verified a posteriori. 
 
<h3>The system start-up process</h3> 
Here the most sensible issue is to be able to correctly start-up the system when an unexpected shutdown has occurred. If that is the case, the log will show an unfinished round; then the system marks all entries after the last complete round as invalid and publishes that round as a 'Big Round'. If the log was consistent, it accesses the last valid 'Round Value' in the log and publishes it as a 'Big Round'. This process insures a fully verifiable behavior; we are able to detect non fully-processed requests. 
 
<h3>The system shutdown process</h3> 
The administrator signals the system to shutdown. No more timestamping requests are accepted. The system waits until the current round is finished and this 'Round Value' is published as 'Big Round'. 
 
<h3>REFERENCES</h3> 
<div style='padding-left: 3em; text-indent: -3em;'> 
<p>[BHS92] D. Bayer, S. Haber, and W.-S. Stornetta. Improving the efficiency and reliability of digital timestamping. In Springer Verlag, editor, Sequences'91: Methods in Communication, Security, and Computer Science, pages 329-334, 1992.</p> 
<p>[HS91] S. Haber and W.-S. Stornetta. How to timestamp a digital document. Journal of Cryptology, 3(2):99-112, 1991.</p> 
<p>[HS97] S. Haber and W.S. Stornetta. Secure names for bit-strings. In Proceedings of the 4th ACM Conference on Computer and Communication Security, pages 28-35. ACM Press, April 1997.</p> 
<p>[MQ97] H. Massias and J.-J. Quisquater. Time and cryptography. Technical report, TIMESEC Project (Federal Governement Project, Belgium), 1997. Available at http://www.dice.ucl.ac.be/crypto/TIMESEC.html.</p> 
<p>[PRQ<sup>+</sup>98] B. Preneel, B. Van Rompay, J.-J. Quiquater, H. Massias, and X. Serret Avila. Design of a timestamping system. Technical report, TIMESEC Project (Federal Governement Project, Belgium), 1998. To be available at http://www.dice.ucl.ac.be/crypto/TIMESEC.html.</p> 
</div> 
</div>" 
 }, 
 { 
 "title": "How to Time-stamp a Digital Document", 
 "subTitle": "S. Haber, W.S. Stornetta, 1991", 
 "published": "Published in: Journal of Cryptology, 1991", 
 "text": "<center> 
<div style='margin:30 0 0 0'> 
<h2>How to Time-stamp a Digital Document</h2> 
</div> 
Stuart Haber<br> 
stuart@bellcore.com<br> 
<br> 
W. Scott Stornetta<br> 
stornetta@bellcore.com<br> 
<br> 
Bellcore<br> 
445 South Street<br> 
Morristown, N.J. O7960-1910<br> 
<br><br> 
</center> 
 <p><strong>Abstract.</strong> The prospect of a world in which all text audio picture and video documents are in digital form on easily modifiable media raises the issue of how to certify when a document was created or last changed The problem is to time-stamp the data, not the medium. We propose computationally practical procedures for digital time-stamping of such documents so that it is infeasible for a user either to back date or to forward date his document even with the collusion of a time-stamping service. Our procedures maintain complete privacy of the documents themselves and require no record-keeping by the time-stamping service. 
 
<div style='line-height: 1.2; margin:20 20 0 20'> 
<font face= 'Times New Roman'> 
Time's glory is to calm contending kings,<br> 
To unmask falsehood and bring truth to light,<br> 
To stamp the seal of time in aged things,<br> 
To wake the morn and sentinel the night,<br> 
To wrong the wronger till he render right <br> 
<br> 
The Rape of Lucrece, l. 941 
</font></div> 
 
<h3>1 Introduction</h3> 
In many situations there is a need to certify the date a document was created or last modified. For example in intellectual property matters, it is sometimes crucial to verify the date an inventor first put in writing a patentable idea, in order to establish its precedence over competing claims.<br> 
One accepted procedure for time-stamping a scientific idea involves daily notations of one's work in a lab notebook. The dated entries are entered one after another in the notebook with no pages left blank. The sequentially numbered sewn in pages of the notebook make it difficult to tamper with the record without leaving telltale signs. If the notebook is then stamped on a regular basis by a notary public or reviewed and signed by a company manager the validity of the claim is further enhanced. If the precedence of the inventor's ideas is later challenged both the physical evidence of the notebook and the established procedure serve to substantiate the inventor's claims of having had the ideas on or before a given date.<br> 
There are other methods of time-stamping. For example, one can mail a letter to oneself and leave it unopened. This ensures that the enclosed letter was created before the time postmarked on the envelope. Businesses incorporate more elaborate procedures into their regular order of business to enhance the credibility of their internal documents, should they be challenged at a later date. For example these methods may ensure that the records are handled by more than one person, so that any tampering with a document by one person will be detected by another. But all these methods rest on two assumptions. First the records can be examined for telltale signs of tampering. Second there is another party that views the document whose integrity or impartiality is seen as vouchsafing the claim. 
<br> 
We believe these assumptions are called into serious question for the case of documents created and preserved exclusively in digital form. This is because electronic digital documents are so easy to tamper with and the change needn't leave any telltale sign on the physical medium. What is needed is a method of time-stamping digital documents with the following two properties. First one must find a way to time-stamp the data itself without any reliance on the characteristics of the medium on which the data appears so that it is impossible to change even one bit of the document without the change being apparent. Second it should be impossible to stamp a document with a time and date different from the actual one. <br> 
The purpose of this paper is to introduce a mathematically sound and computationally practical solution to the time-stamping problem. In the sections that follow we first consider a naive solution to the problem the digital safety deposit box. This serves the pedagogical purpose of highlighting additional difficulties associated with digital time-stamping beyond those found in conventional methods of time-stamping. Successive improvements to this naive solution finally lead to practical ways to implement digital time-stamping. 
 
<h3>2 The Setting</h3> 
The setting for our problem is a distributed network of users perhaps representing individuals different companies or divisions within a company we will refer to the users as <i>clients</i>. Each client has a unique identification number.<br> 
A solution to the time-stamping problem may have several parts. There is a procedure that is performed immediately when a client desires to have a document time-stamped. There should be a method for the client to verify that this procedure has been correctly performed. There should also be a procedure for meeting a third party s challenge to the validity of a document's time-stamp.<br> 
As with any cryptographic problem it is a delicate matter to characterize precisely the security achieved by a time-stamping scheme. A good solution to the time-stamping problem is one for which under reasonable assumptions about the computational abilities of the users of the scheme and about the complexity of a computational problem and possibly about the trustworthiness of the users it is difficult or impossible to produce false time-stamps. Naturally the weaker the assumptions needed the better. 
 
<h3>3 A Naive Solution</h3> 
A naive solution a 'digital safety-deposit box', could work as follows. Whenever a client has a document to be time-stamped he or she transmits the document to a time-stamping service (TSS). The service records the date and time the document was received and retains a copy of the document for safe-keeping. If the integrity of the client's document is ever challenged, it can be compared to the copy stored by the TSS. If they are identical, this is evidence that the document has not been tampered with after the date contained in the TSS records. This procedure does in fact meet the central requirement for the time-stamping of a digital document. However this approach raises several concerns: <br> 
<b>Privacy</b> This method compromises the privacy of the document in two ways: a third party could eavesdrop while the document is being transmitted and after transmission it is available indefinitely to the TSS itself. Thus the client has to worry not only about the security of documents it keeps under its direct control but also about the security of its documents at the TSS. <br> 
<b>Bandwidth and storage</b> Both the amount of time required to send a document for time-stamping and the amount of storage required at the TSS depend on the length of the document to be time-stamped. Thus the time and expense required to time-stamp a large document might be prohibitive. <br> 
<b>Incompetence</b> The TSS copy of the document could be corrupted in transmission to the TSS, it could be incorrectly time-stamped when it arrives at the TSS or it could become corrupted or lost altogether at any time while it is stored at the TSS. Any of these occurrences would invalidate the client's time-stamping claim. <br> 
<b>Trust</b> The fundamental problem remains: nothing in this scheme prevents the TSS from colluding with a client in order to claim to have time-stamped a document for a date and time different from the actual one.<br> 
In the next section we describe a solution that addresses the first three concerns listed above. The final issue trust will be handled separately and at greater length in the following section. 
 
<h3>4 A Trusted Time-stamping Service</h3> 
In this section we assume that the TSS is trusted and describe two improvements on the naive solution above. 
 
<h4>4.1 Hash</h4> 
Our first simplification is to make use of a family of cryptographically secure <i>collision-free hash functions</i>. This is a family of functions <i>h</i> : {0,1}<sup>*</sup> &#8594; {0,1}<sup><i>l</i></sup> compressing bit-strings of arbitrary length to bit-strings of a fixed length <i>l</i> with the following properties: 
<ol> 
<li>The functions <i>h</i> are easy to compute, and it is easy to pick a member of the family at random.</li> 
<li>It is computationally infeasible, given one of these functions <i>h</i>, to find a pair of distinct strings <i>x</i>, <i>x'</i> satisfying <i>h(x)=h(x')</i>. (Such a pair is called a <i>collision</i> for <i>h</i>.) 
</ol> 
The practical importance of such functions has been known for some time and researchers have used them in a number of schemes; see for example [7, 15, 16]. Damg&aring;rd gave the first formal definition, and a constructive proof of their existence, on the assumption that there exist one-way 'claw free' permutations[4]. For this, any 'one-way group action' is sufficient [3].<br>  
Naor and Yung defined the similar notion of 'universal one-way hash functions' which satisfy, in place of the second condition above, the slightly weaker requirement that it be computationally infeasible, given a string <i>x</i> to compute another string <i>x' &#8800; 
 x</i> satisfying <i>h(x)=h(x')</i> for a randomly chosen <i>h</i>. They were able to construct such functions on the assumption that there exist one-to-one one-way functions [17]. Rompel has recently shown that such functions exist if there exist one-way functions at all [20]. See 6.3 below for a discussion of the differences between these two sorts of cryptographic hash functions.<br> 
There are practical implementations of hash functions, for example that of Rivest [19], which seem to be reasonably secure.<br> 
We will use the hash functions as follows. Instead of transmitting his document <i>x</i> to the TSS, a client will send its hash value <i>h(x) = y</i> instead. For the purposes of authentication, time-stamping <i>y</i> is equivalent to time-stamping <i>x</i>. This greatly reduces the bandwidth problem and the storage requirements and solves the privacy issue as well. Depending on the design goals for an implementation of time-stamping there may be a single hash function used by everybody or different hash functions for different users. 
<br> 
For the rest of this paper we will speak of time-stamping hash values y - random-appearing 
bit-strings of a fixed length. Part of the procedure for validating a time-stamp will be to produce the pre-image document <i>x</i> that satisfies <i>h(x) = y</i>; inability to produce such an <i>x</i> invalidates the putative time-stamp. 
 
<h4>4.2 Signature</h4> 
The second improvement makes use of digital signatures. Informally a <i>signature scheme</i> is an algorithm for a party, the signer, to tag messages in a way that uniquely identifies the signer. Digital signatures were proposed by Rabin and by Diffie and Hellman [18, 7]. After a long sequence of papers by many authors, Rompel [20] showed that the existence of one-way functions can be used in order to design a signature scheme satisfying the very strong notion of security that was first defined by Goldwasser, Micali, and Rivest [10].<br> 
With a secure signature scheme available, when the TSS receives the hash value, it appends the 
date and time, then signs this compound document and sends it to the client. By checking the signature, the client is assured that the TSS actually did process the request, that the hash was correctly received, and that the correct time is included. This takes care of the problem of present and future incompetence on the part of the TSS, and completely eliminates the need for the TSS to store records. 
 
<h3>5 Two Time-stamping Schemes</h3> 
<div style='line-height: 1.2; margin:20 0 0 40'> 
<center> 
<i>Sed quis custodiet ipsos Custodes ?</i><br> 
Juvenal, c. 100 A.D.<br> 
But who will guard the guards themselves? 
</center> 
</div> 
<br> 
What we have described so far is, we believe, a practical method for time-stamping digital documents of arbitrary length. However, neither the signature nor the use of hash functions in any way prevents a time-stamping service from issuing a false time-stamp. Ideally we would like a mechanism, which guarantees that no matter how unscrupulous the TSS is, the times it certifies will always be the correct ones, and that it will be unable to issue incorrect time-stamps even if it tries to.<br> 
It may seem difficult to specify a time-stamping procedure so as to make it impossible to produce fake time-stamps. After all if the output of an algorithm <i>A</i>, given as input a document <i>x</i> and some timing information <i>&tau;</i>, is a bit-string <i>c = A(x, &tau;)</i> that stands as a legitimate time-stamp for <i>x</i>, what is to prevent a forger some time later from computing the same timing information <i>&tau;</i> and then running <i>A</i> to produce the same certificate <i>c</i>? The question is relevant even if <i>A</i> is a probabilistic algorithm.<br> 
Our task may be seen as the problem of simulating the action of a trusted TSS in the absence of generally trusted parties. There are two rather different approaches we might take and each one leads to a solution. The first approach is to constrain a centralized but possibly untrustworthy TSS to produce genuine time-stamps in such a way that fake ones are difficult to produce. The second approach is somehow to distribute the required trust among the users of the service. It is not clear that either of these can be done at all. 
 
<h4>5.1 Linking</h4> 
Our first solution begins by observing that the sequence of clients requesting time-stamps and the hashes they submit cannot be known in advance. So if we include bits from the previous sequence of client requests in the signed certificate then we know that the time-stamp occurred after these requests. But the requirement of including bits from previous documents in the certificate also can be used to solve the problem of constraining the time in the other direction because the time-stamping company cannot issue later certificates unless it has the current request in hand.<br> 
We describe two variants of this linking scheme; the first one slightly simpler highlights our main idea, while the second one may be preferable in practice. In both variants the TSS will make use of a collision-free hash function to be denoted <i>H</i>. This is in addition to clients' use of hash functions in order to produce the hash value of any documents that they wish to have time-stamped.<br> 
To be specific, a time-stamping <i>request</i> consists of an <i>l</i>-bit string <i>y</i> (presumably the hash value of the document) and a client identification number ID. We use <i>&sigma; </i>(&sdot;) to denote the signing procedure used by the TSS. The TSS issues signed sequentially numbered time-stamp <i>certificates</i>. In response to the request (<i>y<sub>n</sub>, ID<sub>n</sub></i>) from our client the <i>n</i>th request in sequence the TSS does two things: 
<ol> 
<li> 
The TSS sends our client the signed certificate <i>s = &sigma;</i>(<i>C<sub>n</sub></i>), where the certificate<br> 
<center> 
<i> C<sub>n</sub> = </i>(<i>n, t<sub>n</sub>, ID<sub>n</sub>, y<sub>n</sub>; L<sub>n</sub></i>) 
</center> 
consists of the sequence number <i>n</i> the time <i>t<sub>n</sub></i> the client number <i>ID<sub>n</sub></i> and the hash value <i>y<sub>n</sub></i> from the request, and certain <i>linking information</i>, which comes from the previously issued certificate: <i> L<sub>n</sub> = </i>(<i> t<sub>n-1</sub>, ID<sub>n-1</sub>, y<sub>n-1</sub>, H</i>(<i>L<sub>n-1</sub></i>)).  
</li> 
<li> 
When the next request has been processed the TSS sends our client the identification number <i>ID<sub>n+1</sub></i> for that next request. 
</li> 
</ol> 
  
Having received <i>s</i> and <i>ID<sub>n+1</sub></i> from the TSS, she checks that <i>s</i> is a valid signature of a good certificate, i.e. one that is of the correct form (<i>n, t<sub>n</sub>, ID<sub>n</sub>, y<sub>n</sub>; L<sub>n</sub></i>), containing the correct time <i>t</i>.<br> 
If her time-stamped document <i>x</i> is later challenged the challenger first checks that the time-stamp (<i>s, ID<sub>n+1</sub></i>) is of the correct form (with <i>s</i> being a signature of a certificate that indeed contains a hash of <i>x</i>). In order to make sure that our client has not colluded with the TSS, the challenger can call client <i>ID<sub>n+1</sub></i> and ask him to produce his time-stamp (<i>s', ID<sub>n+2</sub></i>). This includes a signature<br> 
<br> 
<center> 
<i>s' = &sigma;</i>(<i>n+1, t<sub>n+1</sub>, ID<sub>n+1</sub>, y<sub>n+1</sub>; L<sub>n+1</sub></i>) 
</center> 
<br> 
of a certificate that contains in its linking information <i>L<sub>n+1</sub></i> a copy of her hash value <i>y<sub>n</sub></i>. This linking information is further authenticated by the inclusion of the image <i>H</i>(<i>L<sub>n</sub></i>) of her linking information <i>L<sub>n</sub></i>. An especially suspicious challenger now can call up client <i>ID<sub>n+2</sub></i> and verify the next time-stamp in the sequence; this can continue for as long as the challenger wishes. Similarly the challenger can also follow the chain of time-stamps backward beginning, with client <i>ID<sub>n-1</sub></i>.<br> 
Why does this constrain the TSS from producing bad time-stamps? First, observe that the use of the signature has the effect that the <i>only</i> way to fake a time-stamp is with the collaboration of the TSS. But the TSS cannot forward-date a document because the certificate must contain bits from requests that immediately preceded the desired time, yet the TSS has not received them. The TSS cannot feasibly back-date a document by preparing a fake time-stamp for an earlier time, because bits from the document in question must be embedded in certificates immediately following that earlier time, yet these certificates have already been issued. Furthermore, correctly embedding a new document into the already existing stream of time-stamp certificates requires the computation of a collision for the hash function <i>H</i>.<br> 
Thus the only possible spoof is to prepare a fake chain of time-stamps, long enough to exhaust the most suspicious challenger that one anticipates.<br> 
<br> 
In the scheme just outlined, clients must keep all their certificates. In order to relax this requirement, in the second variant of this scheme we link each request not just to the next request but to the next <i>k</i> requests. The TSS responds to the <i>n</i>th request as follows:<br> 
<ol> 
<li> 
As above, the certificate <i>C<sub>n</sub></i> is of the form <i> C<sub>n</sub> = </i>(<i>n, t<sub>n</sub>, ID<sub>n</sub>, y<sub>n</sub>; L<sub>n</sub></i>), where now the linking information <i>L<sub>n</sub></i> is of the form<br> 
<br> 
<center> 
<i>L<sub>n</sub> = </i>[(<i>t<sub>n-k</sub>, ID<sub>n-k</sub>, y<sub>n-k</sub>, H</i>(<i>L<sub>n-k</sub></i>)), . . . ,(<i>t<sub>n-1</sub>, ID<sub>n-1</sub>, y<sub>n-1</sub>, H</i>(<i>L<sub>n-1</sub></i>))]. 
</center> 
<br>  
</li> 
<li> 
After the next <i>k</i> requests have been processed, the TSS sends our client the list (<i>ID<sub>n+1</sub>, . . . , ID<sub>n+k</sub></i>).  
</li> 
</ol> 
  
After checking that this client's time-stamp is of the correct form, a suspicious challenger can ask any one of the next <i>k</i> clients <i>ID<sub>n+i</sub></i> to produce his time-stamp. As above his time-stamp includes a signature of a certificate that contains in its linking information <i>L<sub>n+i</sub></i> a copy of the relevant part of the challenged time-stamp certificate <i>C<sub>n</sub></i>, authenticated by the inclusion of the hash by <i>H</i> of the challenged client's linking information <i>L<sub>n</sub></i>. His time-stamp also includes client numbers (<i>ID<sub>n+i+1</sub>, . . . , ID<sub>n+i+k</sub></i>), of which the last <i>i</i> are new ones; the challenger can ask these clients for their time-stamps, and this can continue for as long as the challenger wishes.<br> 
In addition to easing the requirement that clients save all their certificates, this second variant also has the property that correctly embedding a new document into the already existing stream of time-stamp certificates requires the computation of a simultaneously <i>k</i>-wise collision for the hash function <i>H</i> instead of just a pairwise collision. 
 
<h4>5.2 Distributed trust</h4> 
 
For this scheme, we assume that there is a secure signature scheme so that each user can sign messages, and that a standard secure pseudorandom generator <i>G</i> is available to all users. A <i>pseudorandom generator</i> is an algorithm that stretches short input <i>seeds</i> to output sequences that are indistinguishable by any feasible algorithm from random sequences; in particular, they are unpredictable. Such generators were first studied by Blum and Micali [2] and by Yao [22]. Impagliazzo, Levin and Luby have shown that they exist if there exist one-way functions[12].<br> 
Once again, we consider a hash value <i>y</i> that our client would like to time-stamp. She uses <i>y</i> as a seed for the pseudorandom generator whose output can be interpreted in a standard way as a <i>k</i>-tuple of client identification numbers:<br> 
<br> 
<center> 
<i>G</i>(<i>y</i>) = (<i>ID<sub>1</sub>, ID<sub>2</sub>, . . . , ID<sub>k</sub></i>). 
</center> 
<br> 
 
Our client sends her request (<i>y, ID</i>) to each of these clients. She receives in return from client <i>ID<sub>j</sub></i> a signed message <i>s<sub>j</sub> = &sigma; <sub>j</sub></i>(<i>t, ID, y</i>) that includes the time <i>t</i>. Her time-stamp consists of [(<i>y, ID</i>),(<i>s<sub>1</sub>, . . . , s<sub>k</sub></i>)]. The <i>k</i> signatures <i>s<sub>j</sub></i> can easily be checked by our client or by a would-be challenger. No further communication is required in order to meet a later challenge.<br> 
Why should such a list of signatures constitute a believable time-stamp? The reason is that in these circumstances, the only way to produce a time-stamped document with an incorrect time is to use a hash value <i>y</i> so that <i>G</i>(<i>y</i>) names <i>k</i> clients that are willing to cooperate in faking the time-stamp. If at any time there is at most a constant fraction <i>&epsilon;</i> of possibly dishonest clients the expected number of seeds <i>y</i> that have to be tried before finding a <i>k</i>-tuple <i>G</i>(<i>y</i>) containing only collaborators from among this fraction is <i>&epsilon;<sup>-k</sup></i>. Furthermore, since we have assumed that <i>G</i> is a secure pseudorandom generator, there is no faster way of finding such a convenient seed <i>y</i> than by choosing it at random. This ignores the adversary's further problem, in most real-world scenarios, of finding a plausible document that hashes to a convenient value <i>y</i>.<br> 
The parameter <i>k</i> should be chosen when designing the system so that this is an infeasible computation. Observe that even a highly pessimistic estimate of the percentage of the client population that is corruptible - <i>&epsilon;</i> could be 90% - does not entail a prohibitively large choice of <i>k</i>. In addition, the list of corruptible clients need not be fixed, as long their fraction of the population never exceeds <i>&epsilon;</i>.<br> 
This scheme need not use a centralized TSS at all. The only requirements are that it be possible to call up other clients at will and receive from them the required signatures, and that there be a public directory of clients so that it is possible to interpret the output of <i>G</i>(<i>y</i>) in a standard way as a <i>k</i>-tuple of clients. A practical implementation of this method would require provisions in the protocol for clients that cannot be contacted at the time of the time-stamping request. For example, for suitable <i>k' < k</i>, the system might accept signed responses from any <i>k'</i> of the <k>k</i> clients named by <i>G</i>(<i>y</i>) as a valid time-stamp for <i>y</i> (in which case a greater value for the parameter <i>k</i> would be needed in order to achieve the same low probability of finding a set of collaborators at random).  
 
<h3>6 Remarks 
<h3> 
<h4>6.1 Tradeoffs</h4> 
There are a number of tradeoffs between the two schemes. The distributed-trust scheme has the advantage that all processing takes place when the request is made. In the linking scheme on the other hand the client has a short delay while she waits for the second part of her certificate and meeting a later challenge may require further communication.<br> 
A related disadvantage of the linking scheme is that it depends on at least some clients storing their certificates.<br> 
The distributed trust scheme makes a greater technological demand on the system: the ability to call up and demand a quick signed response at will.<br> 
The linking scheme only locates the time of a document between the times of the previous and the next requests so it is best suited to a setting in which relatively many documents are submitted for time-stamping compared to the scale at which the timing matters.<br> 
It is worth remarking that the time constraining properties of the linking scheme do not depend on the use of digital signatures.<br> 
 
<h4>6.2 Time constraints</h4> 
We would like to point out that our schemes constrain the event of time-stamping both forward and backward in time. However if any amount of time may pass between the creation of a document and when it is time-stamped then no method can do more than forward constrain the time at which the document itself was created. Thus, in general time-stamping should only be considered as evidence that a document has not been back dated.<br> 
On the other hand, if the time-stamping event can be made part of the document creation event then the constraint holds in both directions. For example, consider the sequence of phone conversations that pass through a given switch. In order to process the next call on this switch one could require that linking information be provided from the previous call. Similarly, at the end of the call linking information would be passed onto the next call. In this way, the document creation event (the phone call) includes a time-stamping event, and so the time of the phone call can be fixed in both directions. The same idea could apply to sequential financial transactions, such as stock trades or currency exchanges, or any sequence of electronic interactions that take place over a given physical connection.<br> 
 
<h4>6.3 Theoretical considerations</h4> 
Although we will not do it here, we suggest that a precise complexity theoretic definition of the strongest possible level of time-stamping security could be given along the lines of the definitions given by Goldwasser and Micali [9], Goldwasser, Micali and Rivest [10] and Galil, Haber and Yung [8] for various cryptographic tasks. The time-stamping and the verification procedures would all depend on a <i>security parameter p</i>. A time-stamp scheme would be <i>polynomially secure</i> if the success probability of a polynomially bounded adversary who tries to manufacture a bogus time-stamp is smaller than any given polynomial in 1/<i>p</i> for suficiently large <i>p</i>.<br>  
Under the assumption that there exist one-way claw free permutations we can prove our linking scheme to be polynomially secure. If we assume that there is always at most a constant fraction of corruptible clients, and assuming as well the existence of one way functions (and therefore the existence of pseudorandom generators and of a secure signature scheme), we can prove our distributed trust scheme to be polynomially secure.<br>  
In 4.1 above, we mentioned the difference between 'collision free' and 'universal one-way' hash functions. The existence of one-way functions is sufficient to give us universal one-way hash functions. However, in order to prove the security of our time-stamping schemes we apparently need the stronger guarantee of the difficulty of producing hash collisions that is provided by the definition of collision free hash functions. As far as is currently known, a stronger complexity assumption - namely the existence of claw-free pairs of permutations - is needed in order to prove the existence of these functions. (See also [5] and [6] for further discussion of the theoretical properties of cryptographic hash functions.)<br> 
Universal one-way hash functions were the tool used in order to construct a secure signature 
Scheme. Our apparent need for a stronger assumption suggests a difference perhaps an essential one between signatures and time-stamps. It is in the signer's own interest to act correctly in following the instructions of a secure signature scheme (for example in choosing a hash function at random from a certain set). For time-stamping on the other hand, a dishonest user or a colluding TSS may find it convenient not to follow the standard instructions (for example by choosing a hash function so that collisions are easy to find); the time-stamping scheme must be devised so that there is nothing to be gained from such misbehavior.<br> 
<br> 
If it is possible, we would like to reduce the assumptions we require for secure time-stamping to the simple assumption that one-way functions exist. This is the minimum reasonable assumption for us, since all of complexity based cryptography requires the existence of one-way functions [12, 13] .<br>  
 
<h4>6.4 Practical considerations</h4> 
As we move from the realm of complexity theory to that of practical cryptosystems, new questions arise. In one sense, time-stamping places a heavier demand on presumably one way functions than would some other applications. For example, if an electronic funds transfer system relies on a one-way function for authentication and that function is broken then all of the transfers carried out before it was broken are still valid. For time-stamps, however, if the hash function is broken, then all of the time-stamps issued prior to that time are called into question.<br>  
A partial answer to this problem is provided by the observation that time-stamps can be renewed. Suppose we have two time-stamping implementations and that there is reason to believe that the first implementation will soon be broken. Then certificates issued using the old implementation can be renewed using the new implementation. Consider a time-stamp certificate created using the old implementation that is time-stamped with the new implementation before the old one is broken. Prior to the old implementation's breaking, the only way to create a certificate was by legitimate means. Thus by time-stamping the certificate itself with the new implementation one has evidence not only that the document existed prior to the time of the new time-stamp but that it existed at the time stated in the original certificate.<br> 
<br> 
Another issue to consider is that producing hash collisions alone is not sufficient to break the time-stamping scheme. Rather, meaningful documents must be found which lead to collisions. Thus, by specifying the format of a document class, one can complicate the task of finding meaningful collisions. For example, the density of ASCII-only texts among all possible bit-strings of length <i>N</i> bytes is (2<sup>7</sup> / 2<sup>8</sup>)<sup><i>N</i></sup>, or 1/2<sup><i>N</i></sup>, simply because the high-order bit of each byte is always 0. Even worse, the density of acceptable English text can be bounded above by an estimate of the entropy of English as judged by native speakers [21]. This value is approximately 1 bit per ASCII character, giving a density of (2<sup>1</sup> / 2<sup>8</sup>)<sup><i>N</i></sup>, or 1 / 128<sup><i>N</i></sup>.<br>  
We leave it to future work to determine whether one can formalize the increased difficulty of computing collisions if valid documents are sparsely and perhaps randomly distributed in the input space. Similarly, the fact that a <i>k</i>-way linking scheme requires the would-be adversary to compute <i>k</i>-way collisions rather than collision pairs may be parlayed into relaxing the requirements for the hash function. It may also be worthwhile to explore when there exist hash functions for which there are no <i>k</i>-way collisions among strings in a suitably restricted subset of the input space the security of such a system would no longer depend on a complexity assumption.<br> 
 
<h3>7 Applications</h3> 
Using the theoretically best (cryptographically secure) hash functions, signature schemes, and pseudorandom generators, we have designed time-stamping schemes that possess theoretically desirable properties. However, we would like to emphasize the practical nature of our suggestion: because there are <i>practical</i> implementations of these cryptographic tools, both of our time-stamp schemes can be inexpensively implemented as described. Practical hash functions like Rivest's are quite fast even running on low-end PC's [19].<br> 
<br> 
What kinds of documents would benefit from secure digital time-stamping? For documents that establish the precedence of an invention or idea, time-stamping has a clear value. A particularly desirable feature of digital time-stamping is that it makes it possible to establish precedence of intellectual property without disclosing its contents. This could have a significant effect on copyright and patent law and could be applied to everything from software to the secret formula for Coca-Cola. But what about documents where the date is not as significant as simply whether or not the document has been tampered with? These documents can benefit from time-stamping, too, under the following circumstances. Suppose one can establish that either the necessary knowledge or the motivation to tamper with a document did not exist until long after the document's creation. For example, one can imagine a company that deals with large numbers of documents each day, some few of which are later found to be incriminating. If all the company's documents were routinely time-stamped at the time of their creation then by the time it became apparent which documents were incriminating and how they needed to be modified, it would be too late to tamper with them. We will call such documents <i>tamper-unpredictable</i>. It seems clear that many business documents are tamper-unpredictable. Thus, if time-stamping were to be incorporated into the established order of business, the credibility of many documents could be enhanced.<br>  
A variation that may be particularly useful for business documents is to time-stamp a log of documents rather than each document individually. For example, each corporate document created in a day could be hashed, and the hash value added to the company's daily log of documents. Then, at the end of the business day the log alone could be submitted for time-stamping. This would eliminate the expense of time-stamping each document individually, while still making it possible to detect tampering with each document; one could also determine whether any documents had been destroyed altogether.<br> 
Of course, digital time-stamping is not limited to text documents. Any string of bits can be 
time-stamped, including digital audio recordings, photographs, and full motion videos. Most of these documents are tamper-unpredictable. Therefore, time-stamping can help to distinguish an original photograph from a retouched one, a problem that has received considerable attention of late in the popular press [1, 11]. It is in fact difficult to think of any other algorithmic 'fix' that could add more credibility to photographs, videos, or audio recordings than time-stamping.<br> 
 
<h4>8 Summary</h4> 
In this paper we have shown that the growing use of text audio and video documents in digital form and the ease with which such documents can be modified creates a new problem: how can one certify when a document was created or last modified. Methods of certification or time-stamping must satisfy two criteria. First, they must time-stamp the actual bits of the document making no assumptions about the physical medium on which the document is recorded, Second, the date and time of the time-stamp must not be forgeable.<br>  
We have proposed two solutions to this problem. Both involve the use of one-way hash functions, whose outputs are processed in lieu of the actual documents, and of digital signatures. The solutions differ only in the way that the date and time are made unforgeable. In the first, the hashes of documents submitted to a TSS are linked together, and certificates recording the linking of a given document are distributed to other clients both upstream and downstream from that document. In the second solution, several members of the client pool must time-stamp the hash. The members are chosen by means of a pseudorandom generator that uses the hash of the document itself as seed. This makes it infeasible to deliberately choose which clients should and should not time-stamp a given hash. The second method could be implemented without the need for a centralized TSS at all.<br> 
Finally, we have considered whether time-stamping could be extended to enhance the authenticity of documents for which the time of creation itself is not the critical issue. This is the case for a large class of documents which we call 'tamper unpredictable.' We further conjecture that no purely algorithmic scheme can add any more credibility to a document than time-stamping provides.<br> 
<br> 
<b>Acknowledgements</b><br> 
We gratefully acknowledge helpful discussions with Donald Beaver, Shimon Even, George Furnas, Burt Kaliski, Ralph Merkle, Jeff Shrager, Peter Winkler, Yacov Yacobi, and Moti Yung.<br> 
<br> 
<h4>References</h4> 
<div style='padding-left: 3em; text-indent: -3em;'> 
<p>[1] J Alter. When photographs lie. Newsweek pp. 44-45, July 30, 1900.</p>
<p>[2] M Blum and S Micali. How to generate cryptographically strong sequences of pseudo random bits SIAM Journal on Computing 13(4) :850-864 Nov. 1984.</p> 
<p>[3] G Brassard and M Yung. One way group actions In Advances in Cryptology Crypto Springer Verlag LNCS, to appear.</p> 
<p>[4] I. Damg&aring;rd. Collision-free hash functions and public key signature schemes In Advances in Cryptology Eurocrypt '87, pp 203-217. Springer Verlag, LNCS vol. 304, 1988.</p> 
<p>[5] I. Damg&aring;rd. A design principle for hash functions In Advances in Cryptology- Crypto '89 (ed G Brassard), pp 416-427. Springer Verlag, LNCS vol. 435, 1990.</p>  
<p>[6] A DeSantis and M Yung. On the design of provably secure cryptographic hash functions. In Advances in Cryptology - Eurocrypt '90. Springer Verlag, LNCS, to appear.</p> 
<p>[7] W Diffie and M E Hellman. New directions in cryptography. IEEE Trans. on Inform. Theory, vol. IT-22, Nov. 1976, pp. 644-654.</p>  
<p>[8] Z Galil S Haber and M Yung. Interactive public key cryptosystems. J. of Cryptology, to appear.</p> 
<p>[9] S Goldwasser and S Micali. Probabilistic encryption. JCSS, 28:270-299, April 1984.</p>  
<p>[10] S Goldwasser S, Micali and R Rivest. A secure digital signature scheme. SIAM Journal on Computing, 17(2):281-308, 1988.</p> 
<p>[11] Andy Grundberg. Ask it no questions: The camera can lie. The New York Times, section 2, pp. 1, 29 August 12, 1990.</p>  
<p>[12] R Impagliazzo, L Levin and M Luby. Pseudorandom generation from one way functions. In Proc. 21st STOC, pp 12-24. ACM, 1989.</p> 
<p>[13] R Impagliazzo and M Luby. One way functions are essential for complexity-based cryptography. In Proc. 30th FOCS, pp. 230-235. IEEE, 1989.</p>  
<p>[14] H M Kanare. Writing the laboratory notebook, p. 117. American Chemical Society, 1985.</p>  
<p>[15] R C Merkle. Secrecy authentication, and public key systems. Ph.D. thesis, Stanford Univeristy, 1979.</p> 
<p>[16] R C Merkle. One-way hash functions and DES. In Advances in Cryptology - Crypto '89 (ed. G Brassard), pp. 428-446. Springer Verlag, LNCS, vol 435, 1900.</p>  
<p>[17] M Naor and M Yung. Universal one-way hash functions and their cryptographic applications. In Proc 21st STOC, pp. 33-43. ACM, 1989.</p>  
<p>[18] M O Rabin. Digitalized signatures. In Foundations of Secure Computation (ed R.A. DeMillo et. al.) pp. 155-168. Academic Press , 1978.</p> 
<p>[19] R Rivest. The MD4 message digest algorithm. In Advances in Cryptology - Crypto '90. Springer Verlag, LNCS, to appear.</p> 
<p>[20] J Rompel. One-way functions are necessary and sufficient for secure signatures. In Proc. 22nd STOC, pp. 387-394. ACM, 1990.</p>  
<p>[21] C Shannon. Prediction and entropy of printed English. Bell System Technical Journal, vol. 30 pp. 50-64, 1951.</p>  
<p>[22] A C Yao. Theory and applications of trapdoor functions. In Proc. 23rd FOCS, pp. 80-91. IEEE, 1982.</p>  
</div> 
</div>" 
 }, 
 { 
 "title": "Improving the Efficiency and Reliability of Digital Time-Stamping", 
 "subTitle": "D. Bayer, S. Haber, W.S. Stornetta, 1993", 
 "published": "Published in: Sequences II: Methods in Communication, Security and Computer Science, 1993", 
 "text": "<center> 
<div style='margin:30 0 0 0'> 
<h2>Improving the Efficiency and Reliability of Digital Time-Stamping</h2> 
</div> 
Dave Bayer<br> 
Barnard College<br> 
Columbia University<br> 
New York, N.Y. 10027 U.S.A.<br> 
<font face= 'Courier New'>dab@math.columbia.edu</font> 
<br> 
<br> 
Stuart Haber<br> 
Bellcore<br> 
445 South Street<br> 
Morristown, N.J. 07960 U.S.A.<br> 
<font face= 'Courier New'>stuart@bellcore.com</font> 
<br> 
<br> 
W. Scott Stornetta<br> 
Bellcore<br> 
445 South Street<br> 
Morristown, N.J. 07960 U.S.A.<br> 
<font face= 'Courier New'>stornetta@bellcore.com</font> 
<br> 
<br> 
March 1992<br> 
</center> 
<br> 
<br> 
<p><strong>Abstract.</strong> To establish that a document was created after a given moment in time, it is necessary to report events that could not have been predicted before they happened. To establish that a document was created before a given moment in time, it is necessary to cause an event based on the document, which can be observed by others. Cryptographic hash functions can be used both to report events succinctly, and to cause events based on documents without revealing their contents. Haber and Stornetta have proposed two schemes for digital time-stamping which rely on these principles [HaSt 91].<br> 
We reexamine one of those protocols, addressing the resource constraint required for storage and verification of time-stamp certificates. By using trees, we show how to achieve an exponential increase in the publicity obtained for each time-stamping event, while reducing the storage and the computation required in order to validate a given certificate.<br> 
We show how time-stamping can be used in certain circumstances to extend the useful lifetime of different kinds of cryptographic certifications of authenticity, in the event that the certifying protocol is compromised. This can be applied to digital signatures, or to time-stamping itself, making the digital time-stamping process renewable. 
</p> 
<h3>1 Introduction</h3> 
Causality fixes events in time. If an event was determined by certain earlier events, and determines certain subsequent events, then the event is sandwiched securely into its place in history. Fundamentally, this is why paper documents have forensic qualities allowing them to be accurately dated and examined for signs of after-the-fact tampering. However, documents kept in digital form need not be closely tied to any physical medium, and tampering may not leave any tell-tale signs in the medium.<br> 
Could an analogous notion of causality be applied to digital documents to correctly date them, and to make undetected tampering infeasible? Any solution would have to time-stamp the data itself, without any reliance on the properties of a physical medium, and would be especially useful and trustworthy if the date and time of the time-stamp could not be forged.<br> 
In [HaSt 91], Haber and Stornetta posed this problem, and proposed two solutions. Both involve the use of cryptographic hash functions (discussed in 2 below), whose 
outputs are processed in lieu of the actual documents. In the <i>linking</i> solution, the hash values of documents submitted to a time-stamping service are chained together in a linear list into which nothing can feasibly be inserted or substituted and from which nothing can feasibly be deleted. This latter property is insured by a further use of cryptographic hashing. In the <i>random-witness</i> solution, several members of the client pool must date and sign the hash value; their signatures form a composite certification that the time-stamp request was witnessed. These members are chosen by means of a pseudorandom generator that uses the hash of the document itself as a seed. This makes it infeasible to deliberately choose which clients should and should not act as witnesses.<br> 
In both of these solutions, the record-keeping requirements per time-stamping request are proportional to the number of (implicit) observers of the event. In 3 below 
we address the following problem: What if an immense flood of banal transactions want their time-stamps to become part of the historical record, but history just isn't interested? We propose to merge many unnoteworthy time-stamping events into one noteworthy event, using a tournament run by its participants. The winner can be easily and widely publicized. Each player, by remembering a short list of opponents, can establish participation in the tournament. We do this by building trees in place of the linked list of the linking solution, thus achieving an exponential increase in the number of observers. Such hash trees were previously used by Merkle [Merk 80] for a different purpose, to produce authentication certificates for a directory of public enciphering keys.<br> 
<br> 
There are several ways in which a cryptographic system can be compromised. For example, users' private keys may be revealed; imprudent choice of key-lengths may be overtaken by an increase in computing power; and improved algorithmic techniques may render feasible the heretofore intractable computational problem on which the system is based. In 4 below we show how time-stamping can be used in certain circumstances to extend the useful lifetime of digital signatures. Applying the same technique to time-stamping itself, we demonstrate that digital time-stamps can be renewed.<br> 
<br> 
Finally, in 5 we discuss the relationships between the different methods of digital time-stamping that have been proposed.<br> 
<br> 
 
<h3>2 Hash functions</h3> 
The principal tool we use in specifying digital time-stamping schemes, here as in [HaSt 91], is the idea of a cryptographic hash function. This is a function compressing digital documents of arbitrary length to bit-strings of a fixed length, for which it is computationally infeasible to find two different documents that are mapped by the function to the same <i>hash value</i>. (Such a pair is called a <i>collision</i> for the hash function.) Hence it is infeasible to fabricate a document with a given hash value. In particular, a fragment of a document cannot be extended to a complete document with a given hash value, unless the fragment was known before the hash value was created. In brief, a hash value must follow its associated document in time.<br> 
There are practical implementations of hash functions, for example those of Rivest [Riv 90] and of Brachtl, et al. [BC+ 88], which seem to be reasonably secure. 
In a more theoretical vein, Damgard defined a family of <i>collision-free hash functions</i> to be a family of functions <i>h</i> : {0, 1}<sup>*</sup> &#8594; {0, 1}<sup>l</sup></i> compressing bit-strings of arbitrary length to bit-strings of a fixed length <i>l</i>, with the following properties: 
<ol> 
<li> 
The functions <i>h</i> are easy to compute, and it is easy to pick a member of the family at random. 
</i> 
<li> 
It is computationally infeasible, given a random choice of one of these functions 
<i>h</i>, to find a pair of distinct strings <i>x, x'</i> satisfying <i>h</i>(<i>x</i>) = <i>h</i>(<i>x'</i>). 
</i> 
</ol> 
He gave a constructive proof of their existence, on the assumption that there exist one-way 'claw-free' permutations [Dam 87]. For further discussion of theoretical questions relating to the existence of families of cryptographic hash functions (variously defined) see [HaSt 91] and the references contained therein. 
In the rest of this paper, we will assume that a cryptographic hash function <i>h</i> is given: either a particular practical implementation, or one that has been chosen at random from a collision-free family. 
 
 
<h3>3 Trees</h3> 
In the linking scheme, the challenger of a time-stamp is satisfied by following the linked chain from the document in question to a time-stamp certificate that the challenger considers trustworthy. If a trustworthy certificate occurs about every <i>N</i> documents, say, then the verification process may require as many as <i>N</i> steps. We may reduce this cost from <i>N</i> to log <i>N</i> , as follows.<br> 
Suppose we combine the hash values of two users' documents into one new hash value, and publicize only the combined hash value. (We will consider a 'publicized' value to be trustworthy.) Either participant, by saving his or her own document as well as the other contributing hash value, can later establish that the document existed before the time when the combined hash value was publicized.<br> 
More generally, suppose that <i>N</i> hash values are combined into one via a binary tree, and the resulting single hash value is widely publicized. To later establish 
priority, a participant need only record his own document, as well as the [log<sub>2</sub> <i>N</i>] hash values that were directly combined with the document's hash value along the 
path to the root of the tree. In addition, along with each combining hash value, the user needs to record its 'handedness,' indicating whether the newly computed value was placed before or after the combining hash value. Verification consists simply of recomputing the root of the tree from this data.<br> 
Once hashing functions are chosen, such a scheme could be carried out like a world championship tournament: Heterogeneous local networks could govern local subtrees under the scrutiny of local participants, and regional 'winners' could be combined into global winners under the scrutiny of all interested parties. Global communication facilities are required, and a broadcast protocol must be agreed upon, but no centralized service bureau need administer or profit from this system. For example, given any protocol acceptable separately to the western and eastern hemispheres for establishing winners for a given one-hour time period, the winners can be broadcast by various members of the respective hemispheres, and anyone who wants to can carry out the computations to determine the unique global winner for that time period. Winners for shorter time periods can similarly be combined into unique winners for longer time periods, by any interested party.<br> 
At a minimum, daily global winners could be recorded in newspaper advertisements, to end up indefinitely on library microfilm. The newspaper functions as a widely available public record whose long-term preservation at many locations makes tampering very difficult. An individual who retains the set of values tracing the path between his document and the hash value appearing in the newspaper could establish the time of his document, without any reliance on other records. Anyone who wishes to be able to resolve time-stamps to greater accuracy needs only to record time-stamp broadcasts to greater accuracy.<br> 
 
<h3>4 Using time-stamping to extend the lifetime of a threatened cryptographic operation</h3> 
The valid lifetime of a digitally signed document can be extended with digital time-stamping, in the following way. Imagine an implementation of a particular digital signature scheme, with a particular choice of key lengths, and consider a plaintext document <i>D</i> and its digital signature &sigma; by a particular user. Now let the pair (<i>D, &sigma;</i>) be time-stamped. Some time later the signature may become invalid, for any of a variety of reasons, including the compromise of the user's private key, an increase in available computing power making signatures with keys of that length unsafe, or the discovery of a basic flaw in the signature scheme. At that point, the document-signature pair becomes questionable, because it may be possible for someone other than the original signer to create valid signatures.<br> 
However, if the pair (<i>D, &sigma;</i>) was time-stamped at a time before the signature was compromised, then the pair still constitutes a valid signature. This is because it is known to have been created at a time when only legitimate users could have produced it. Its validity is not in question even though new signatures generated by the compromised method might no longer be trustworthy.<br> 
The same technique applies to other instances of cryptographic protocols. In particular, the technique can be used to renew the time-stamping process itself. Once again, imagine an implementation of a particular time-stamping scheme, and consider the pair (<i>D, C</i>), where <i>C</i> is a valid time-stamp certificate (in this implementation) for the document <i>D</i>. If (<i>D, C</i>) is time-stamped by an improved time-stamping method before the original method is compromised, then one has evidence not only that the document existed prior to the time of the new time-stamp, but that it existed at the time stated in the original certificate. Prior to the compromise of the old implementation, the only way to create a certificate was by legitimate means. (The ability to renew time-stamps was mentioned in [HaSt 91] but an incorrect method was given. The mistake of the previous work was in assuming that it is sufficient to renew the certificate alone, and not the document-certificate pair. This fails, of course, if the compromise in question is a method of computing hash collisions for the hash function used in submitting time-stamp requests.) 
 
<h3>5 Different methods of time-stamping</h3> 
To date, three different digital time-stamping techniques have been proposed: linear linking, random witness and linking into trees. What is the relationship between them? Does one supersede the others? Initially, one might think that trees satisfy time-stamping requirements better than the two previously proposed methods, because the tree protocol seems to reduce storage requirements while increasing the number of interested parties who serve as witnesses. But there are other tradeoffs to consider.<br> 
First we consider the linking protocol. In certain applications, such as a laboratory notebook, it is crucial not only to have a trustworthy date for each entry but also to establish in a trustworthy manner the exact sequence in which all entries were made. Linear linking of one entry to the next provides the most straightforward means of achieving this.<br> 
Next we consider the difference between the random-witness method and the tree method. While trees increase the number of witnesses to a given time-stamping event in proportion to the number of documents time-stamped, they do not guarantee a minimum number of witnesses. Neither do they guarantee that witnesses will retain their records. In contrast, in random witness the effective number of witnesses is the entire population, though only a small fraction are actually involved in any given time-stamping event. Furthermore, the set of signatures computed by the randomwitness protocol explicitly creates a certificate which is evidence that a time-stamping event was widely witnessed. Thus, the protocol does not depend for its final validity on witnesses keeping records. Random witness is somewhat analogous to placing an advertisement in the newspaper, as discussed earlier, but with an additional refinement. Like the newspaper ad, it is effectively a widely witnessed event, but in addition it creates a record of the witnessing.<br> 
Given these tradeoffs, we imagine that the three methods may be used in a complementary fashion, as the following example illustrates. An individual or company might use linear linking to time-stamp its own accounting records, sending the final summary value for a given time period to a service maintained by a group of individuals or parties. This service constructs linked trees at regular intervals. The root of each tree is then certified as a widely viewed event by using the random-witness protocol among the participants. In this way, individual and group storage needs can be minimized, and the number of events which require an official record of witnessing can be greatly reduced. 
 
<h3>References</h3> 
<div style='padding-left: 3em; text-indent: -3em;'> 
<p>[BC+ 88] B. O. Brachtl, D. Coppersmith, M. M. Hyden, S. M. Matyas, Jr., C. H. W. Meyer, J. Oseas, Sh. Pilpel, and M. Shilling. Data authentication using modification detection codes based on a public one way encryption function. U.S. Patent No. 4,908,861, issued March 13, 1990. (Cf. C. H. Meyer and M. Shilling, Secure program load with modification detection code. In Securicom 88: 6&egrave;me Congr&egrave;s mondial de la protection et de la s&eacute;curit&eacute; informatique et des communications, pp. 111-130 (Paris, 1988).)</p> 
<p>[Dam 87] I. Damg&aring;rd. Collision-free hash functions and public-key signature schemes. In Advances in Cryptology-Eurocrypt '87, Lecture Notes in Computer Science, Vol. 304, pp. 203-217, Springer-Verlag (Berlin, 1988).</p> 
<p>[HaSt 91] S. Haber, W. S. Stornetta, How to time-stamp a digital document, Journal of Cryptography, Vol. 3, No. 2, pp. 99-111 (1991). (Presented at Crypto '90.)</p> 
<p>[Merk 80] R. C. Merkle, Protocols for public key cryptosystems. In Proc. 1980 Symp. on Security and Privacy, IEEE Computer Society, pp. 122-133 (Apr. 1980).</p> 
<p>[Riv 90] R. L. Rivest. The MD4 message digest algorithm. In Advances in Cryptology-Crypto '90, Lecture Notes in Computer Science, Vol. 537 (ed. A. J. Menezes, S. A. Vanstone), pp. 303-311, Springer-Verlag (Berlin, 1991).</p> 
</div> 
</div>" 
 }, 
 { 
 "title": "Secure Names for Bit-Strings", 
 "subTitle": "S. Haber, W.S. Stornetta, 1997", 
 "published": "Published in: Proceedings of the 4th ACM Conference on Computer and Communications Security, 1997", 
 "text": "<center> 
<div style='margin:30 0 0 0'> 
<h2>Secure Names for Bit-Strings</h2> 
<br> 
</div> 
Stuart Haber<br> 
<font face= 'Courier New'>stuart@surety.com</font> 
<br> 
<br> 
W. Scott Stornetta<br> 
<font face= 'Courier New'>scotts@surety.com</font><br> 
<br><br><br> 
</center> 
<p><strong>Abstract.</strong> The increasing use of digital documents, and the need to refer to them conveniently and unambiguously, raise an important question: can one 'name' a digital document in a way that conveniently enables users to find it, and at the same time enables a user in possession of a document to be sure that it is indeed the one that is referred to by the name? One crucial piece of a complete solution to this problem would be a method that provides a cryptographically verifiable label for any bit-string (for example, the content, in a particular format, of the document). This problem has become even more acute with the emergence of the WorldWide Web, where a document (whose only existence may be on-line) is now typically named by giving its URL, which is merely a pointer to its virtual location at a particular moment in time.<br> 
Using a one-way hash function to call files by their hash values is cryptographically verifiable, but the resulting names are unwieldy, because of their length and randomness, and are not permanent, since as time goes on the hash function may become vulnerable to attack. We introduce procedures to create names that are short and meaningful, while at the same time they can persist indefinitely, independent of the longevity of any given hash function. This is done by naming a bit-string according to its position in a growing, directed acyclic graph of one-way hash values. We prove the security of our naming procedures under a reasonable complexitytheoretic cryptographic assumption, and then describe practical uses for these names. An implementation of our naming scheme has been in use since January 1995.<br></p> 
 
<h3>1 Introduction</h3> 
Users of documents need to refer to those documents in order to keep records and in order to communicate with other users of the documents. In practice, users name their documents in various ways. A name must be unambiguous, at least in the context of its use; this requires some connection between the name and the integrity of the document it names. 
In the traditional world of paper documents, there arc usually reasonable guarantees of this connection. In the case of printed books and magazines, large print runs that arc the result of single typesetting efforts make it easier to be confident that all copies of a printed document are the same, with a definite name printed in a conventional place in the document. Making a change to a paper document of any sort, even a small change, typically leaves forensic evidence. A characteristic feature of digital documents, by contrast, is that they are easy to copy and to alter. The naming problem is especially troubling if the document exists only on-line and never in conventional paper-based form. For on. line documents, a useful naming scheme would allow users to employ the name to find documents, as well as to check the integrity of the documents that they find. A number of proposals have been made for such naming systems (sec e.g. [SM 94, KW 95, BD+95]). These proposals address in different ways the problem of how to 'resolve' the name into a location where the document might be found.<br> 
It is the integrity-checking problem that we address in this work: how to make sure that the bit-string content of a given digital document is indeed the same as the bit-string that was intended. Heretofore, two different sorts of mechanisms have been proposed, digital signatures and one-way hash values.<br> 
Having the author or publisher of a document compute a digital signature for its bit-string content is a reasonable use of cryptographic tools for this purpose. (See, for example, [R 95, M 94].) However, the ability to validate many digital signatures requires the presence of a public-key infrastructure, and the trustworthiness of the validation procedure relies on the assurance that the signer's private signing key is indeed secure. For some on-line documents, the infrastructure and these assurances may not be available. For long-lived documents, the security of the binding between a public key and the person or role of the putative signer becomes even more problematic. (A general solution to the latter problem is briefly described in &sect;5.)<br> 
Thus it would be useful to have an integrity mechanism, depending on the exact contents of the bit-string in question, that does not depend on the secrecy of a cryptographic key. A natural choice for such a mechanism is the use of a one-way hash function, naming any bit-string by its hash value. (See, for example, [BD+95].) However, while this method is intrinsically verifiable, there are several inconvenient features: 
<ul> 
<li> 
A desirable feature for the names given to a collection of objects is that they be long-lasting, if not permanent. (This is one of the functional requirements for URNs [SM 94].) But as technology advances, any particular choice of a presumably one-way function for a naming scheme becomes less secure, so that it must be replaced (see [Doh 96a, Doh 96b]). The unpleasant result is that the name of a long-lived document will need to change over time. 
</li> 
<li> 
Hash values are too long for a human user to remember or even to communicate easily to another human being. ( For example, it is currently recommended that one-way hash functions compute outputs that are at the very least 128 bits long; this is the output length of MD5 [Riv 92]. In a 6 bit/character encoding, this is 22 alphanumeric characters long.) 
</li> 
<li> 
The author of a bit-string document has no control over the form of its name. A one-way hash function produces a random-appearing bit-string of the appropriate length as the hash value of a document. Thus, inconvenient as it may be for the author, there will be no connection between the names of documents that are related to each other, either in form or in substance. 
</li> 
</ul> 
 
This paper presents a method for naming bit-strings that retains the verifiable security of hash-based names, while avoiding the constraints listed above, as well as avoiding the use of secret cryptographic keys. The method is a variation on the digital time-stamping schemes of [HS 91, BHS 93]. In summary, the essence of the new scheme is to keep a repository of hash values that depend on many bit-string inputs, and to name each bit-string by a concise description of a location in the repository to which it can be securely 'linked' by a one-way hashing computation.<br> 
An implementation of our naming scheme has been running continuously since January 1995 [Sur 95].<br> 
The rest of this paper is organized as follows. After technical preliminaries in &sect;2, including both a brief discussion of the wider problem of naming digital documents as well as a formal description of our sub-problem, we present our scheme and prove its security in &sect;3. Motivated by the explosive growth of the Internet, we mention a number of possible applications of our scheme in &sect;4. In &sect;5, we describe a method for extending the lifetime of our digital names beyond the cryptographically secure lifetime of the hash functions used to compute them. Finally, we discuss several different sorts of practical implementation in &sect;6. 
 
<h3>2 Preliminaries</h3> 
<h4>2.1 Naming digital documents</h4> 
A naming system for digital documents should perform (at least) two functions. It should help the user (1) to find the document named; and (2) to reassure himself or herself that a given document is indeed the correct one, i.e. that it is indeed a perfect copy of the document that was intended.<br> 
To enable both these functions, the 'name' could include both identification information as well as location information. System design may include procedures for registration of new documents, for finding a document given its name, for updating a document's location information, and for validating the integrity of a document. Typically, there is a server that 'resolves' or translates a name into location information, for example into a URL or a list of URLs. The name may include other information about the document, including such data as title, author, format, price, and access privileges.<br> 
A large body of work has been devoted to the difficult problem of designing and building a naming system of this sort so that it is usable, useful, and reliable. In [SM 94] a set of functional requirements is described for Uniform Resource Names (URNs), the names to be assigned by a naming system for resources on the Internet. A number of researchers have built naming systems, including, among others, [KW 95, BD+ 95]. (This is by no means an exhaustive list.)<br> 
 
In this work we propose a new method for the integrity-checking piece of naming systems for digital documents. All previously proposed systems that included mechanisms for checking the integrity of the bit-string or bit-strings that make up a digital document have used either digital signatures or one-way hash functions for this purpose. For certain applications, these methods have the problems described in 
&sect;1 above. 
 
<h4>2.2 Hash functions</h4> 
The principal technical tool we use in this paper is that of a one-way hash function. This is a function compressing digital documents of arbitrary length to bit-strings of a fixed length, for which it is computationally infeasible to find two different documents that are mapped by the function to the same hash value. (Such a pair is called a <i>collision</i> for the hash function.)<br> 
 
Practical proposals for one-way hash functions include those of MD5 [Riv 92], SHA-I [NIST 94], and RIPEMD-160 [DBP 96]. Though the actual security of these functions (i.e., the precise difficulty of computing collisions for them) is not known, they are now in more or less widespread use.<br> 
<b>Definition</b> In a more theoretical vein, Damg&aring;rd defined a family of <i>collision-free hash functions</i> to be a family {<i>H<sub>k</sub></i>}<i><sub>k</sub></i> of sets of functions (indexed by a security parameter <i>k</i>) with the following properties: 
<ol> 
<li> 
Each <i>H<sub>k</sub></i> is a set of functions <i>h</i> : {0,1}<sup>*</sup> &#8594; {0,1}<sup><i>k</i></sup> that are computable in polynomial time. 
</li> 
<li> 
Given <i>k</i>, it is easy to choose <i> h &#8712; H<sub>k</sub> </i> at random. 
</li> 
<li> 
It is computationally infeasible, given a random choice of one of these functions, to find a collision for the function. More precisely, for any polynomial algorithm <i>A</i>, for any positive constant <i>c</i>,<br> 
Pr[<i>h</i> &#8592; <i>H<sub>k</sub></i>; (<i>x</i>, <i>x'</i>) &#8592; <i>A</i>(<i>h</i>) : <i>x</i> &#8800; <i>x'</i> , <i>h</i>(<i>x</i>) = <i>h</i>(<i>x'</i>)] < k <sup> -c </sup><br> 
for sufficiently large <i>k</i>. 
</li> 
</ol> 
Damg&aring;rd gave a constructive proof of their existence, on the assumption that there exist families of one-way 'clawfree' permutations [Dam 87]. More generally, any 'one-way group action' is sufficient [BY 90]. Concretely, the construction can be based on the difficulty either of factoring or of the discrete logarithm function. (As usual, the collision adversary A in condition (3) above can be uniform or non-uniform depending on the precise form of the hypothesis made on the computational complexity of the underlying problem.) For a variety of reasons, none of the known theoretical constructions of collision-free hash functions are practical.<br> 
 
In practice, the infeasibility of computing collisions for a particular hash function depends on the current state of the art, both the current state of algorithmic knowledge about attacking the function in question, as well as the computational speed and memory available in the best current computers. As the state of the art advances, it is likely that a function that was once securely one-way will eventually cease to be so. For example, Dobbertin's recently announced attacks on MD4 and MD5 have considerably reduced the community's confidence in the strength of these two functions [Doh 96a., Doh 96b, Doh 96c]. In &sect;5 below we offer a solution to the problem this poses for certain practical systems whose real-world security depends on the actual infeasibility of specific computational tasks.<br> 
We refer the reader to [Pre 93) for a thorough discussion of one-way hash functions. 
 
<h4>2.3 Theoretical model</h4> 
We emphasize that this is a theoretical description of the problem of verifiably 'naming' bit-strings, which is only a piece of the larger problem of naming digital documents. 
The setting for our problem is a distributed network of parties. The network may include a <i>server S</i> as well as a <i>repository R</i>; parties may query the repository, asking for a copy of a particular item it contains.<br> 
 
<b>Definition</b> A <i>naming scheme</i> for this setting consists of: 
<ul> 
<li> 
a <i>security parameter k</i>; 
</li> 
<li> 
a polynomial-time <i>naming protocol N</i>, possibly requiring interaction with the <i>server S</i>, taking as input a bit-string <i>x</i> , and producing as output a <i>name n</i> for <i>x</i>, a <i>certificate c</i>, and the addition of items to the <i>repository R</i>; and 
</li> 
<li> 
a polynomial-time <i>validation protocol V</i>, that takes as input a triple (<i>x</i>, <i>n</i>, <i>c</i>) and the result of a query to <i>R</i>, and either accepts or rejects its inputs. 
</li> 
</ul> 
 
If (<i>n</i>, <i>c</i>) is the output of an invocation of <i>N</i> on input <i>x</i>, then <i>V</i> accepts the input (<i>x</i>, <i>n</i>, <i>c</i>) when it is accompanied by a correct response to a query to <i>R</i>.<br> 
It is possible, of course, to specify a naming scheme that does not require a server or a repository. In that case, the naming protocol and the validation protocol may simply be algorithms that any party in the network may invoke without interacting with outside parties.<br> 
 
<b>Definition</b> A <i>counterfeiting adversary</i> to a naming scheme [<i>N</i>, <i>V</i>, <i>S</i>] is a (possibly probabilistic) algorithm <i>A</i> that performs as follows. Given <i>k</i> as input, <i>A</i> produces (polynomially many) naming requests <i>x<sub>1</sub>, x<sub>2</sub></i>, . . . ; for each <i>x<sub>i</sub></i> <i>A</i> is given the output of <i>N</i>(<i>x<sub>i</sub></i>). The request <i>x<sub>i+1</sub></i> may be computed after <i>A</i> has received the response to its <i>i</i>th request. In addition, <i>A</i> may make (polynomially many) queries to <i>R</i>. Finally (after <i>q</i> naming requests, say), <i>A</i>'s output is of the form (<i>x</i>, <i>n</i>, <i>c</i>). This output is a <i>successful counterfeit</i> if x &#8800; x' (for <i>i</i> = 1 . . . <i>q</i>) and <i>V</i> accepts (<i>x</i>, <i>n</i>, <i>c</i>) (after a correct response to any queries to <i>R</i>).<br> 
<b>Definition</b> A naming scheme is <i>secure</i> if for any polynomially bounded counterfeiting adversary <i>A</i> and for any positive constant<i>c</i>, <i>A</i>'s success probability on input <i>k</i> is less than <i>k <sup> -c </sup></i> for sufficiently large <i>k</i>.<br> 
 
To illustrate our definitions, here is a simple example of a naming scheme, where the only role of the server is to announce its random choice of a hash function <i> h &#8712; H<sub>k</sub></i>. The naming procedure is just <i>N</i>(<i>x</i>) = <i>h</i>(<i>x</i>) with no certificates, and <i>V</i> accepts (<i>x</i>, <i>n</i>) if <i>n</i> = <i>h</i>(<i>x</i>). It is clear that this defines a secure naming scheme as long as <i>H<sub>k</sub></i> is the <i>k</i>th set in a family of collision-free hash functions. 
We remark that the roles of <i>S</i> as trusted server and <i>R</i> as trustworthy repository in these definitions are just an artifact of how we have chosen to present and to analyze our naming schemes, allowing a clean separation between issues of the security of the scheme itself and issues of how it might be implemented in practice. 
 
<h4>2.4 Digital time-stamping</h4> 
Our solution to the naming problem builds on the work of (HS 91) and [BHS 93], whose authors describe several procedures with which users can certify (the bit-string contents of) their digital documents, computing for any particular document a time-stamp certificate. Later, any user of the system can validate a document-certificate pair; that is, he or she can use the certificate to verify that the document existed, in exactly its current form, at the time asserted in the certificate. It is infeasible to compute an illegitimate document-certificate pair that will pass the validation procedure.<br> 
Because we use it directly in our naming scheme, we summarize here one digital time-stamping scheme. A central 'coordinating server' receives certification requests - essentially, hash values of files - from users. At regular intervals, the server builds a binary tree out of all the requests received during the interval, following Merkle's tree authentication technique; the leaves are the requests, and each internal node is the hash of the concatenation of its two children [Merk 80]. The root of this tree is hashed together with the previous 'interval hash' to produce the current interval hash, which is placed in a widely available repository. The server then returns to each requester a time-stamp certificate consisting of the time at which the interval ended, along with the list of sibling hash values along the path leading from the requester's leaf up to the interval hash, each one accompanied by a bit indicating whether it is the right or the left sibling. The scheme also includes a validation procedure, allowing a user to test whether a document has been certified in exactly its current form, by querying the repository for the appropriate interval hash, and comparing it against a hash value appropriately recomputed from the document and its certificate.<br> 
It is noteworthy that the trustworthiness of the certificates computed in this scheme depends only on the integrity of the repository, and not (for example) on trusting that a particular private key has not been compromised or that a particular party's computation has been performed correctly. 
 
<h3>3 A naming scheme for bit-strings</h3> 
Next we describe a naming scheme for a network that includes a server <i>S</i> and a repository <i>R</i>. Many executions of <i>N</i> and of <i>V</i> may be performed concurrently in the network. We assume that there exists a family {<i>H<sub>k</sub>}<sub>k</sub></i> of collision-free hash functions. Given an initial choice of security parameter <i>k</i>, <i>S</i> announces to all parties its random choice of a one-way hash function <i> h &#8712; H<sub>k</sub> </i>. Our scheme is a variation on the time-stamping scheme described in &sect;2.4 above, with <i>S</i> playing the role of the coordinating server that computes certificates in response to requests and makes additions to the repository <i>R</i>.<br> 
We abbreviate a bit-string's certificate by omitting the list of hash values, leaving only a pointer to the relevant interval hash (for example, the time at which it was computed), and an encoding of the position of the request in the tree for that interval (for example, the sequence of left or right bits). It is this abbreviation that we propose to use as the name of the bit-string.<br> 
 
More explicitly, an invocation of <i>N</i> on input <i>x</i> begins with the computation of <i>y</i> = <i>h</i>(<i>x</i>), and the submission of <i>y</i> to <i>S</i>, which includes <i>y</i> as one of the leaves of the tree being built in the current time interval. At the end of the interval, having built a tree of height <i>l</i> (that includes the previous interval hash), <i>S</i> places the root of the tree in <i>R</i> as the current interval hash with label <i>t</i>, say. <i>S</i> responds to the request by returning the certificate <i>c</i> = [<i>t</i>; (<i>z<sub>1</sub></i>, <i>b<sub>1</sub></i>), . . . , (<i>z<sub>l</sub></i>, <i>b<sub>l</sub></i>)], where each b<sub>i</sub> = L or R. Finally, the name returned by <i>N</i> for argument <i>x</i> is <i>n</i> = [<i>t</i>; <i>b<sub>1</sub></i>, . . . , <i>b<sub>l</sub></i>].<br> 
One uses the entire certificate in order to validate that a particular string correctly names a particular bit-string document, first by checking that the putative name was correctly extracted from the certificate, and then by following the usual validation procedure for the document-certificate pair (recomputing the path from the leaf to the root of the tree).<br> 
To be precise, <i>V</i> operates as follows, given as inputs a document <i>x</i>, a name <i>n</i> = [<i>t</i>; <i>b<sub>1</sub></i>, . . . , <i>b<sub>l</sub></i>], and a certificate <i>c</i> = [<i>t'</i>; (<i>z<sub>1</sub>, b'<sub>1</sub></i>), . . . , (<i>z<sub>l</sub>, b'<sub>l</sub></i>)]: First, <i>V</i> checks that <i>t</i> = <i>t'</i> and that each <i>b<sub>i</sub></i> = <i>b'<sub>i</sub></i>. Next, <i>V</i> computes <i>y<sub>1</sub> &#8592; h</i>(<i>x</i>) and then (for <i>i</i> &#8592; 1 . . . <i>l</i>) if <i>b<sub>i</sub></i> = L then <i>y<sub>i+1</sub></i> &#8592; <i>h</i>(<i>z<sub>i</sub> &sdot; y<sub>i</sub></i>) else if <i>b<sub>i</sub></i> = R then <i>y<sub>i+1</sub></i> &#8592; <i>h</i>(<i>y<sub>i</sub> &sdot; z<sub>i</sub></i>). Finally, <i>V</i> queries <i>R</i> for the hash value stored at location <i>t</i>, and checks that it is identical to <i>y<sub>t+1</sub></i>. <i>V</i> accepts if all these checks are satisfied and rejects otherwise.<br> 
Figure 1 below illustrates the tree built by <i>S</i> for a time interval during which it received eight requests, containing the eight hash values <i>a</i>, <i>b</i>, <i>c</i>, <i>d</i>, <i>e</i>, <i>f</i> , <i>g</i>, and <i>h</i>. In this diagram, <i>ab</i> is the hash of the concatenation of <i>a</i> and <i>b</i>, etc., and <i>I H<sub>t</sub></i> and <i>I H<sub>t-1</sub></i> are the respective interval hashes for the current and the previous intervals. The certificate computed by S for the third request (the one containing hash value <i>c</i>), for example, is the following:<br> 
<center> 
[<i>t</i>; (<i>d, R</i>), (<i>ab, L</i>), (<i>eh, R</i>), (<i>I H<sub>t-1</sub>, L</i>)]. 
</center> 
<h4>3.1 Security</h4> 
The security of this naming scheme follows directly from the infeasibility of computing hash collisions for functions from {<i>H<sub>k</sub></i>}<i><sub>k</sub></i>, since the only possible counterfeit names include hash collisions. In essence, if x is a bit-string on which <i>N</i> was never invoked during a run, any triple (<i>x</i>, <i>n</i>, <i>c</i>) that <i>V</i> will accept (after the correct response to a query to <i>R</i>) will include a hash collision for the function <i>h</i> announced by <i>S</i> at the beginning of the run: either <i>x</i> itself or one of the hash values <i>z<sub>i</sub></i> in <i>c</i> (when combined on the left or the right with <i>y<sub>i</sub></i>) collides with another argument to <i>h</i> whose hash value was computed during the run. Therefore we have the following theorem.<br> 
<br> 
<b>Theorem 1</b> <i>If </i>{<i>H<sub>k</sub></i>}<i><sub>k</sub></i> <i> is a family of collision-free hash functions, then the naming scheme </i>[<i>N, V, S</i>]<i> described above is secure.</i><br> 
<br> 
Because the reduction in the proof is so direct, it is easy to give an 'exact security' analysis (cf. [Lev 85, BKR 94]) of the strength of this scheme, whether the hash functions used are from the collision-free family provided by a theoretical cryptographic assumption or rather practical hash functions, as in the implementations described in &sect;6 below. 
 
<h4>3.2 Variations on the scheme</h4> 
Of course, the secure verifiability of the names assigned by the scheme described above does not depend on the particular combination of binary trees and linked lists used. By systematically invoking the hash function on pairs or ordered lists of hash values, new hash values can be computed from old ones so as to form a directed acyclic graph (by directing an edge from each of the inputs to the hash value output). Design considerations (including those discussed in &sect;6.1 below) may dictate several different combinatorial structures for this directed graph.<br> 
Whatever the structure of the growing graph of hash values, it is secured by making portions of the graph widely witnessed and widely available. To insure the verifiability of the names, it suffices that every document in the naming structure be linked by a directed path to a widely witnessed hash value; a standard ordering of the incoming edges at each node can be used to encode the path. Then the name of a document is given by this encoding of its location in the graph, together with a pointer to the hash value at the end of the path, and the argument of Theorem 1 applies.<br> 
For example, in one variation of the scheme described above, a list of documents may be used to build a local tree (following Merkle, again), whose root is sent off in turn as a request to the coordinating server. The location information for a document in this 'tree-of-trees' scheme can be written as a position in the server's tree followed by a position in the local tree.<br> 
In another variation, the widely witnessed hash values in the repository could consist simply of a linked list (as in the simple linking scheme of [HS 91]). In this case the location information for a document is a simple pointer into the repository. 
 
<h3>4 Applications</h3> 
The problem of naming digital documents might have seemed like a curiosity only a few years ago. However, with the growth in use of the Internet, more and more people need to be able to refer confidently to meaningful bit-sequences. The problem is now a matter of immediate practical concern.<br> 
The problem has become especially acute with the emergence of the World-Wide Web. Jumping from one URL (Uniform Resource Locator) to the next in a sequence of WWW documents may seem at first to be exactly analogous to following a bibliographic reference in a traditional scholarly paper. In fact it is something quite different: a URL is only a pointer to a location, with no guarantee that what a user finds there today is the same reference that the author originally intended. If on-line citations include secure names for the bit-string contents of the documents cited, then it is possible to traverse a path of citations with confidence that one is indeed following the authors' intentions. This ability would be especially useful for the many documents on the World-Wide Web that exist only on-line.<br> 
In most electronic commerce systems, transaction records of all sorts are kept on-line, and it would be useful to have a cryptographically secure means of assigning serial numbers or tracking numbers to these records.<br> 
<br> 
<br> 
<img src='securenames_figure1.png' width='450px'> 
<br><br> 
Figure 1: 8-leaf tree for the example of &sect;3.<br> 
<br> 
Software code is another class of digital document for which it would be useful to have an easy way for a short name to carry a guarantee of integrity. A user who downloads software (along with its naming certificate) from a site on the Net can be sure of its integrity if he or she is able to check that the code is correctly named by a short string of letters and numbers. Here, of course, bit-string equality is exactly the point. The great strength of using secure names in this application is that the short name of a program is considerably easier to distribute widely and robustly than the program itself. (It is also easier to distribute reliably than the sort of public-key infrastructure information that is required in order to use digital signatures in order to validate the integrity of code.)<br> 
For another example of a type of large digital document whose integrity matters a great deal, consider the case of genetic data. Scientists now routinely download others' data sets for use in their own research. The use of our naming scheme would allow the user to be sure of the data's integrity, as well as providing a convenient and verifiable way to cite the data in published descriptions of the work that was done with it. 
 
<h3>5 Long-lived names</h3> 
The technique described in [BHS 93] for renewing cryptographic certifications of authenticity applies directly to the certificates of the present naming scheme. 
The renewing process works as follows. Let us suppose that an implementation of a particular time-stamping system is in place, and consider the pair (<i>x</i> , <i>C</i>), where <i>C</i> is a valid time-stamp certificate (in this implementation) for the bit-string <i>x</i>. Now suppose that an improved time-stamping system is implemented and put into practice - by replacing the hash function used in the original system with a new hash function, or even perhaps after the invention of a completely new algorithm. Further suppose that the pair (<i>x</i> , <i>C</i>) is time-stamped by the new system, resulting in a new certificate <i>C'</i>, and that some time later, i.e. at a definite later date, the original method is compromised. <i>C'</i> provides evidence not only that the document contents x existed prior to the time of the new time-stamp, but that it existed at the time stated in the original certificate, <i>C</i>; prior to the compromise of the old implementation, the only way to create a certificate was by legitimate means. (It is similarly recommended that if a digitally signed document is likely to be important for a long time - perhaps longer than the signer's key will be valid - then the document-signature pair should be time-stamped [BHS 93, Odl 95, HKS 95].)<br> 
In our naming schemes, the verifiable name for the bit-string <i>x</i> is a standard abbreviation <i>a</i> for its original certificate <i>C</i>. In order that a continue to be verifiable as a name for <i>x</i>, the certificate <i>C</i> should be renewed (as above) from time to time as new time-stamping systems are put in place. As long as this is done, <i>a</i> is still a verifiable name for <i>x</i>. There is now an additional step to the procedure for validating the name: after checking that a is correctly extracted from <i>C</i>, one must follow the usual time-stamp validation procedure for the certificate, which now includes both the original system validation of (<i>x, C</i>) and the new-system validation of [(<i>x, C</i>), <i>C'</i>]. We note that in practice this additional validation step would be automated, and would not at all affect the convenient use of a to name <i>x</i>. 
 
<h3>6 Practical implementations</h3> 
A practical implementation of a naming scheme cannot use the known theoretical constructions of collision-free hash functions. If the decision is made to use practical one-way hash functions such as MD5, then users of the system do not need to trust the server's random choice of a function <i>h &#8712; H<sub>k</sub></i>. (However, they do have to hope that the hash function chosen is one-way in practice; see section &sect;5 for one way to allay users' concerns on this score.)<br> 
The naming scheme described in &sect;3 above, based on the digital time-stamping scheme described in &sect;2.4, was implemented by Surety Technologies, and has been in continuous commercial use since January 1995. The implementation uses practical hash functions; specifically, the current implementation uses <i>h</i>(<i>x</i>) = (MD5(<i>x</i>), SHA(<i>x</i>)) as the hash value for any argument x. A number of supplemental mechanisms are employed in order to maintain the integrity and wide distribution of the repository [Sur 95].<br> 
The names assigned by our scheme are indeed concise growing essentially as slowly as possible while still providing unique names. If the repository contains <i>n</i> interval hashes, and no more than <i>m</i> naming requests are received during each interval, the names can be written with at most lg<sub>2</sub> <i>nm</i> bits. Just to give a numerical example, a repository representing a thousand requests per minute for the length of a century requires 36-bit names; in the MIME encoding (six bits per alphanumeric character) such a name can be jotted down with six characters, while hash-value names of this length are completely insecure. 
 
<h4>6.1 Meaningful names</h4> 
There are several variations of our naming scheme that allow an author a fair measure of control over the names of his or her documents, so that the author can choose a verifiable name that is meaningful in one or another useful way.<br> 
First, and most obviously, observe that in the scheme described in detail in &sect;3 a convenient way to encode the location in the repository to which a document's contents are linked is by the date and time at which the interval hash at that location was computed. Instead of (e.g.) a MIME encoding of the number of seconds since a moment in early 1970 (Unix standard time), it would often be useful to express at least a part of this date and time in human readable form.<br> 
In a slight variation, we can allow 'personalized' naming requests, as follows. Suppose that the repository items are formatted in a standard way every day, and let <i>F</i>(&sdot;) denote any standard mapping from ASCII-encoded strings to the list of daily repository locations. When the server receives a personalized naming request that includes the ASCII string s, the request is held until the appropriate moment in the day and then linked to the widely witnessed hash value stored at location <i>F</i>(<i>s</i>); in this way, s is made to be part of the name of the documents included in those special naming requests. Thus, for example, the author of <i>The History of Computers in Zurich</i> can arrange for the verifiable name of its bit-string contents to have the form ['The History of Computers in Zurich' date suffix], where suffix includes a few bits of disambiguating information that distinguishes this request from all others that were linked to the same repository location.<br> 
In another example, consider the tree-of-trees variation briefly mentioned in &sect;3.2. An author can name a multi-part document by placing the contents of each successive part at consecutive leaf nodes of a local tree. The resulting request to the server gives the consecutive parts of the document consecutive local positions and therefore consecutive names. Furthermore, the other portions of these consecutive names are identical, explicitly encoding the fact that they are parts of the same document. And local trees can have sub-trees, so that our historian can arrange to name the <i>i</i>th section of the <i>j</i>th chapter of his masterpiece ['The History of Computers in Zurich' infix <i>i.j</i>], for all appropriate pairs (<i>i, j</i>).<br> 
More complicated ways of structuring the parts of a document can similarly be encoded in the verifiable names assigned by our naming scheme. Note that conventional naming schemes do allow for encoding document structure into names, but not in a verifiable manner. 
In another variation, a table of contents for a long or complicated multi-part document can be included in a standard place in the request-for example, as its last piece. The table of contents may contain more or less detailed descriptions of the parts of the document. At a later time, together with a list of documents to be authenticated and their certificates, such an authenticated table of contents can be used to verify (1) that each document in the list is an exact copy of one that was registered with the table of contents, and (2) that none of the documents in the list are missing. 
<h3>Acknowledgements</h3> 
We would like to thank Ralph Merkle, R. Venkatesan, Matt Franklin, Avi Rubin, Bill Arms, and Dave Richards for helpful discussions about this work. We would also like to thank the anonymous referees for their very useful suggestions.<br> 
 
<h3>References</h3> 
<div style='padding-left: 3em; text-indent: -3em;'> 
<p>[BHS 93] D. Bayer, S. Haber, and W.S. Stornetta. Improving the efficiency and reliability of digital time-stamping. In Sequences II: Methods in Communication, Securit y, and Computer Science, ed. R.M. Capocelli, A. De Santis, U. Vaccaro, pp. 329-334, Springer-Verlag, New York (1993).</p> 
<p>[BKR 94] M. Bellare, J. Kilian, and P. Rogaway. The security of cipher block chaining. In Advances in Cryptology-Crypto '94, Lecture Notes in Computer Science, Vol. 839, ed. Y. Desmedt, pp. 94-107, Springer-Verlag (1994).</p> 
<p>[BY 90] G. Brassard and M. Yung. One-way group actions. In Advances in Cryptology-Crypto '90, Lecture Notes in Computer Science, Vol. 537, pp. 94-107, Springer-Verlag (1991).</p> 
<p>[BD+ 95] S. Browne, J. Dongarra, S. Green, K. Moore, T. Pepin, T. Rowan, and R. Wade. Locationindependent naming for virtual distributed software repositories. Univeristy of Tennessee Computer Science TR 95-278 (1995). (Available at http://www.cs.utk.edu/&tilde;library/TechReports/1995/).</p> 
<p>[Dam 87] I. Damg&aring;rd. Collision-free hash functions and public-key signature schemes. In Advances in Cryptology-Eurocrypt '87, Lecture Notes in Computer Science, Vol. 304, pp. 203-217, Springer-Verlag (Berlin, 1988).</p> 
<p>[Dob 96a] H. Dobbertin. Cryptanalysis of MD4. In Fast Software Encr yption, Lecture Notes in Computer Science, Vol. 1039, ed. D. Gollman, pp. 53-69, Springer-Verlag (Berlin, 1996). 
<p>[Dob 96b] H. Dobbertin. Cryptanalysis of MD5 compress. Private communication (May 1996). 
Described by B. Preneel, Rump Session, Eurocrypt '96 (May 1996).</p> 
<p>[Dob 96c] H. Dobbertin. The status of MD5 after a recent attack. CrytoBytes, Vol. 2, No. 2 (Summer 1996).</p> 
<p>[DBP 96] H. Dobbertin, A. Bosselaers, and B. Preneel. RIPEMD-160: A strengthened version of RIPEMD. In Fast Software Encr yption, Lecture Notes in Computer Science, Vol. 1039, ed. D. Gollman, pp. 71-82, Springer-Verlag (Berlin, 1996).</p> 
<p>[HKS 95] S. Haber, B. Kaliski, and W.S. Stornetta. How do digital time-stamps support digital signatures? CryptoBytes, Vol. 1, No. 3 (Autumn 1995). (Available at http://www.rsa.com/rsalabs/pubs/cryptobytes.html)</p> 
<p>[HS 91] S. Haber and W.S. Stornetta. How to timestamp a digital document. Journal of Cryptology, Vol. 3, No. 2, pp. 99-111 (1991).</p> 
<p>[KW 95] R. Kahn and R. Wilensky. A framework for distributed digital object services. Corporation for National Research Initiatives technical report cnri.dlib/tn95-01 (May 1995). (Available at http: //www.cnri.reston.va.us/.)</p> 
<p>[Lev 85] L.A. Levin. One-way functions and pseudorandom generators. In Proceedings of the 17th Annual Symposium on Theory of Computing, pp. 363-365, ACM (1987).</p> 
<p>[Merk 80] R.C. Merkle. Protocols for public key cryptosystems. In Proc. 1980 Symposium on Security and Privac y, IEEE Computer Society, pp. 122-133 (April 1980).</p> 
<p>[M 94] J.W. Moore. The use of encryption to ensure the integrity of reusable software components. In Proc. Srd International Conj. on Software Reusabilit y, IEEE Computer Society Press (November 1994).</p> 
<p>[NIST 94] National Institute of Standards and Technology. Secure Hash Standard. NIST Federal Information Processing Standard Publication 180-1 (May 1994).</p> 
<p>[Odl 95] A. Odlyzko. The future of integer factorization. CrytoBytes, Vol. 1, No. 2 (1995),</p> 
<p>[Pre 93] B. Preneel. Anal ysis and Design of Cryptographic Hash Functions. Ph.D. dissertation, Katholieke Universiteit Leuven (January 1993).</p> 
<p>[Riv 92] R. Rivest. The MD5 Message-Digest Algorithm. Internet Network Working Group Request for Comments 1321 (April 1992).</p> 
<p>[R 95] A. Rubin. Trusted distribution of software over the Internet. In Internet Society 1995 Symposium on Network and Distributed System Security (1995).</p> 
<p>[SM 94] K. Sollins and L. Masinter. Functional requirements for Uniform Resource Names. Internet Network Working Group Request for Comments 1737 (December 1994).</p> 
<p>[Sur 95] Surety Technologies, Inc. Answers to Frequently Asked Questions about the Digital Notary TM System. http: I/www. surety. com (since January 1995).</p> 
</div> 
</div>" 
 }, 
 { 
 "title": "Hashcash - A Denial of Service Counter-Measure", 
 "subTitle": "A. Back, 2002", 
 "published": "Source: http://www.hashcash.org/papers/hashcash.pdf (2002)", 
 "text": "<center> 
<div style='margin:30 0 0 0'> 
<h2>Hashcash - A Denial of Service Counter-Measure</h2> 
<br> 
</div> 
<center> 
Adam Back<br> 
<font face= 'Courier New'>adam@cypherspace.org</font> 
<br> 
<br> 
1st August 2002 
<br><br><br> 
</center> 
<div align='left' style='line-height: 1.5'> 
 
<p><strong>Abstract.</strong> Hashcash was originally proposed as a mechanism to throttle systematic abuse of un-metered internet resources such as email, and anonymous remailers in May 1997. Five years on, this paper captures in one place the various applications, improvements suggested and related subsequent publications, and describes initial experience from experiments using hashcash.<br> 
The hashcash CPU cost-function computes a token which can be used as a proof-of-work. Interactive and non-interactive variants of cost-functions can be constructed which can be used in situations where the server can issue a challenge (connection oriented interactive protocol), and where it can not (where the communication is store-and- forward, or packet oriented) respectively.</p> 
 
<h3>1 Introduction</h3> 
Hashcash [1] was originally proposed as a mechanism to throttle systematic abuse of un-metered internet resources such as email, and anonymous remailers in May 1997. Five years on, this paper captures in one place the various applications, improvements suggested and related subsequent publications, and describes initial experience from experiments using hashcash.<br> 
The <i>hashcash</i> CPU cost-function computes a token which can be used as a proof-of-work. Interactive and non-interactive variants of cost-functions can be constructed which can be used in situations where the server can issue a challenge (connection oriented interactive protocol), and where it can not (where the communication is store-and- forward, or packet oriented) respectively.<br> 
At the time of publication of [1] the author was not aware of the prior work by Dwork and Naor in [2] who proposed a CPU pricing function for the application of combatting junk email. Subsequently applications for costfunctions have been further discussed by Juels and Brainard in [3]. Jakobsson and Juels propose a dual purpose for the work spent in a cost-function: to in addition perform an otherwise useful computation in [4]. 
 
 
<h3>2 Cost-Functions</h3> 
A cost-function should be efficiently verifiable, but parameterisably expensive to compute. We use the following notation to define a cost-function.<br> 
In the context of cost-functions we use client to refer to the user who must compute a token (denoted <i>&Tau;</i>) using a cost-function MINT() which is used to create tokens to participate in a protocol with a server. We use the term mint for the cost-function because of the analogy between creating cost tokens and minting physical money. 
The server will check the value of the token using an evaluation function VALUE(), and only proceed with the protocol if the token has the required value.<br> 
The functions are parameterised by the amount of work that the user will have to expend on average to mint a token.<br> 
With <i>interactive cost-functions</i>, the server issues a challenge <i>C</i> to the client - the server uses the CHAL() function to compute the challenge. (The challenge function is also parameterised by the work factor.)<br> 
<br> 
<center> 
<img src='hashcash_fig1.png' width='350px'> 
</center> 
<br> 
With <i>non-interactive cost-functions</i> the client choses it's own challenge or random start value in the MINT() function, and there is no CHAL() function.<br> 
<br> 
<center> 
<img src='hashcash_fig2.png' width='350px'> 
</center> 
<br> 
Clearly a <i>non-interactive cost-function</i> can be used in an interactive setting, whereas the converse is not possible.<br> 
<h4>2.1 Publicly Auditable, Probabilistic Cost</h4> 
<ul> 
<li> 
A <b>publicly auditable</b> cost-function can be efficiently verified by any third party without access to any trapdoor or secret information. (When we say publicly auditable we mean implicitly that the cost-function is efficiently publicly auditable compared to the cost of minting the token, rather than auditable in the weaker sense that the auditor could repeat the work done by the client.) 
</li> 
<li> 
A <b>fixed cost</b> cost-function takes a fixed amount of resources to compute. The fastest algorithm to mint a fixed cost token is a deterministic algorithm. 
</li> 
<li> 
A <b>probabilistic cost</b> cost-function is one where the cost to the client of minting a token has a predictable expected time, but a random actual time as the client can most efficiently compute the cost-function by starting at a random start value. Sometimes the client will get lucky and start close to the solution.<br> 
<br> 
There are two types of probabilistic cost bounded probabilistic cost and unbounded probabilistic cost. 
<ul> 
<li>An <b>unbounded probabilistic cost</b> cost-function, can in theory take forever to compute, though the probablity of taking significantly longer than expected decreases rapidly towards zero. (An example would be the cost-function of being required to throw a head with a fair coin; in theory the user could be unlucky and end up throwing many tails, but in practice the probability of not throwing a head for throws tends towards 0 rapidly as<br>lim<sub>k &#8594; &infin;</sub> (&frac12;)<sup>k</sup> = 0.) 
</li> 
<li>With a <b>bounded probabilistic cost</b> cost-function there is a limit to how unlucky the client can be in it's search for the solution; for example where the client is expected to search some key space for a known solution; the size of the key space imposes an upper bound on the cost of finding the solution. 
</li> 
</li> 
</ul> 
</ul> 
 
<h4>2.2 Trapdoor-free</h4> 
A disadvantage of known solution cost-functions is that the challenger can cheaply create tokens of arbitrary value. This precludes public audit where the server may have a conflict of interests, for example in web hit metering, where the server may have an interest to inflate the number of hits on it's page where it is being paid per hit by an advertiser. 
 
<ul> 
<li> 
A <i>trapdoor-free</i> cost-function is one where the server has no advantage in minting tokens. 
</li> 
</ul> 
 
An example of a trapdoor-free cost-function is the Hashcash [1] cost-function. Juels and Brainard's client-puzzle cost-function is an example of a <i>known-solution</i> cost-function where the server has an advantage in minting tokens. Client-puzzles as specified in the paper are in addition not publicly auditable, though this is due to a storage optimization and not inherent to their design. 
  
<h3>3 The Hashcash cost-function</h3> 
Hashcash is a non-interactive, publicly auditable, trapdoor-free cost function with unbounded probabilistic cost.<br> 
First we introduce some notation: consider bitstring <i>s = </i>{<i>0, 1</i>}<sup>*</sup>, we define [<i>s</i>]<sub>i</sub> to means the bit at offset <i>i</i>, where [<i>s</i>]<sub>1</sub> is the left-most bit, and [<i>s</i>]<sub>|s|</sub> is the right-most bit. [<i>s</i>]<sub>i . . . j</sub> means the bit-wise substring between and including bits <i>i</i> and <i>j</i>, [<i>s</i>]<sub>i . . . j</sub> = [<i>s</i>]<sub>i</sub> || . . . || [<i>s</i>]<sub>j</sub>. So <i> s = </i>[<i>s</i>]<sub>1 . . . |s|</sub></i>.<br> 
We define a binary infix comparison operator where b is the length of the common left-substring from the two bit-strings.<br> 
<br> 
<center> 
<img src='hashcash_fig3.png' width='220px'> 
</center> 
<br> 
Hashcash is computed relative to a service-name <i>s</i>, to prevent tokens minted for one server being used on another (servers only accept tokens minted using their own service-name). The service-name can be any bit-string which uniquely identifies the service (eg. host name, email address, etc).<br> 
The hashcash function is defined as (note this is an improved simplifed variant since initial publication see note in section 5:<br> 
<br> 
<center> 
<img src='hashcash_fig4.png' width='350px'> 
</center> 
<br> 
The hashcash cost-function is based on finding <i>partial hash collisions</i> on the all 0 bits <i>k</i>-bit string 0<sup>k</sup>. The fastest algorithm for computing partial collisions is brute force. There is no challenge as the client can safely choose his own random challenge, and so the hashcash cost-function is a <i>trapdoor-free</i> and <i>non-interactive</i> cost-function. In addition the Hashcash cost-function is <i>publicly auditable</i>, because anyone can efficiently verify any published tokens. (In practice |<i>x</i>| should be chosen to be large enough to make the probability that clients reuse a previously used start value negligible; |<i>x</i>| = 128 bits should be enough even for a busy server.)<br> 
The server needs to keep a double spending database of spent tokens, to detect and reject attempts to spend the same token again. To prevent the database growing indefinitely, the service string can include the time at which it was minted. This allows the server to discard entries from the spent database after they have expired. Some reasonable expiry period should be chosen to take account of clock inaccuracy, computation time, and transmission delays.<br> 
Hashcash was originally proposed as a counter-measure against email spam, and against systematic abuse of anonymous remailers. It is necessary to use non-interactive cost-functions for these scenarios as there is no channel for the server to send a challenge over. However one advantage of interactive cost-functions is that it is possible to prevent pre-computation attacks. For example, if there is a cost associated with sending each email this may be sufficient to limit the scale of email abuse perpetrated by spammers; however for a pure DoS-motivated attack a determined adversary may spend a year pre-computing tokens to all be valid on the same day, and on that day be able to temporarily overload the system.<br> 
It would be possible to reduce the scope for such pre-computation attacks by using a slowly changing beacon (unpredictable broadcast authenticated value changing over time) such as say this weeks winning lottery numbers. In this event the current beacon value is included in the start string, limiting pre-computation attacks to being conducted within the time period between beacon value changes. 
 
<h3>4 Interactive Hashcash</h3> 
With the interactive form of hashcash, for use in interactive settings such as TCP, TLS, SSH, IPSEC etc connection establishment a challenge is chosen by the server. The aim of interactive hashcash is to defend server resources from premature depletion, and provide graceful degradation of service with fair allocation across users in the face of a DoS attack where one user attempts to deny service to the other users by consuming as many server resources as he can. In the case of security protocols such as TLS, SSH and IPSEC with computationally expensive connection establishment phases involving public key crypto the server resource being defended is the servers available CPU time. 
The interactive hashcash cost-function is defined as follows:<br> 
<br> 
<center> 
<img src='hashcash_fig5.png' width='380px'> 
</center> 
<br> 
<h4>4.1 Dynamic throttling</h4> 
With interactive hashcash it becomes possible to dynamically adjust the work factor required for the client based on server CPU load. The approach also admits the possibility that interactive hashcash challenge-response would only be used during periods of high load. This makes it possible to phase-in DoS resistent protocols without breaking backwards compatibility with old client software. Under periods of high load non-hashcash aware clients would be unable to connect, or would be placed in a limited connection pool subject to older less effective DoS counter-measures such as random connection dropping. 
 
<h4>4.2 hashcash-cookies</h4> 
With connection-slot depletion attacks such as the syn-flood attack, and straight-forward TCP connection-slot depletion the server resource that is being consumed is space available to the TCP stack to store per-connection state.<br> 
In this scenario it may be desirable to avoid keeping per connection state, until the client has computed a token with the interactive hashcash cost-function. This defense is similar to the syn-cookie defense to the syn-flood attack, but here we propose to additionally impose a CPU cost on the connecting machine to reserve a TCP connection-slot. 
To avoid storing the challenge in the connection state (which itself consumes space) the server may choose to compute a keyed MAC of the information it would otherwise store and sent it to the client as part of the challenge so it can verify the authenticity of the challenge and token when the client returns them. (This general technique - of sending a record you would otherwise store together with a MAC to the entity the information is about - is referred to as a <i>symmetric key certificate</i>.) This approach is analogous to the technique used in syn-cookies, and Juels and Brainard proposed a related approach but at the application protocol level in their client-puzzles paper.<br> 
For example with MAC function keyed by server key the challenge MAC could be computed as:<br> 
<br> 
<center> 
<img src='hashcash_fig6.png' width='350px'> 
</center> 
<br> 
The client must send the MAC <i>m</i>, and the challenge <i>c</i> and challenge parameters <i>p</i> with the response token so that the server can verify the challenge and the response. The server should also include in the MAC the connection parameters, at minimum enough to identify the connection-slot and some time measurement or increasing counter <i>t</i> so that old challenge responses can not be collected and re-used after the connection-slots are free. The challenge and MAC would be sent in the TCP SYN-ACK response message, and the client would include the interactive hashcash token (challenge-response) in the TCP ACK message. As with syn-cookies, the server would not need to keep any state per connection prior to receiving the TCP ACK.<br> 
For backwards compatibility with syn-cookie aware TCP stacks, a hashcash-cookie aware TCP stack would only turn on hashcash-cookies when it detected that it was subject to a TCP connection-depletion attack. Similar arguments as given by Dan Bernstein in [5] can be used to show that backwards compatibility is retained, namely under syn-flood attacks Bernstein's arguments show how to provide backwards compatibility with non syn-cookie aware implementations; similarly under connection-depletion attack hashcash-cookies are only turned on at a point where service would anyway otherwise be unavailable to a non-hashcash-cookie aware TCP stack.<br> 
As the flood increases in severity the hashcash-cookie algorithm would increase the collision size required to be in the TCP ACK message. The hashcash-cookie aware client can still connect (albeit increasinly slowly) with a more fair chance against the DoS attacker presuming the DoSer has limited CPU resources. The DoS attacker will effectively be pitting his CPU against all the other (hashcash-cookie aware) clients also trying to connect. Without the hashcashcookie defense the DoSer can flood the server with connection establishments and can more easily tie up all it's slots by completing n connections per idle connection time-out where <i>n</i> is the size of the connection table, or pinging the connections once per idle connection time-out to convince the server they are alive.<br> 
Connections will be handed out to users collectively in rough proportion to their CPU resources, and so fairness is CPU resource based (presuming each user is trying to open as many connections as he can) so the result will be biased in favor of clients with fast processors as they can compute more interactive-hashcash challenge-response tokens per second. 
 
<h3>5 Hashcash improvements</H3> 
In the initially published hashcash scheme, the target string to find a hash collision on was chosen <i>fairly</i> by using the hash of the service-name (and respectively the service-name and challenge in the interactive setting). A subsequent improvement suggested independently by Hal Finney [6] and Thomas Boschloo [7] for hashcash is to find a collision against a fixed output string. Their observation is that a fixed collision target is also fair, simpler and reduces verification cost by a factor of 2. A fixed target string which is convenient to compare trial collisions against is the <i>k</i>-bit string 0<sup>k</sup> where <i>k</i> is the hash output size. 
 
<h3>6 Low Variance</h3> 
Ideally cost-function tokens should take a predictable amount of computing resources to compute. Juels and Brainard's client-puzzle construction provides a probabilistic bounded-cost by issuing challenges with <i>known-solutions</i>, however while this limits the theoretical worst case running time, it makes limited practical difference to the variance and typical experienced running time. The technique of using known solutions is also not applicable to the non-interactive setting. It is an open question as to whether there exist probabilistic bounded-cost, or fixed-cost non-interactive cost-functions with the same order of magnitude of verification cost as hashcash.<br> 
The other more significant incremental improvement due to Juels and Brainard is the suggestion to use multiple sub-puzzles with the same expected cost, but <i>lower variance</i> in cost. This technique should be applicable to both the non-interactive and interactive variants of hashcash. 
 
<h4>6.1 Non-Parallelizability and Distributed DoS</h4> 
Roger Dingledine, Michael Freedman and David Molnar put forward the argument that non-parallelizable cost-functions are less vulnerable to Distributed DoS (DDoS) in chapter 16 of [8]. Their argument is that non-parallelizable cost-functions frustrate DDoS because the attacker is then unable sub-divide and farm out the work of computing an individual token.<br> 
The author described a fixed-cost cost-function in [9] using Rivest, Shamir and Wagner's time-lock puzzle [10] which also happens to be non-parallelizable. The time-lock puzzle cost-function can be used in either an interactive or non-interactive setting as it is safe for the user to chose their own challenge. The applicability of Rivest et al's time-lock puzzle as a cost-function was also subsequently observed by Dingledine et al in [8].<br> 
For completeness we present the time-lock puzzle based fixed-cost and non-parallelizable cost-function from [9] here:<br> 
<br> 
<center> 
<img src='hashcash_fig7.png' width='400px'> 
</center> 
<br> 
The client does not know <i>&Phi;</i>(<i>n</i>), and so the most efficient method for the client to calculate MINT() is repeated exponentiation, which requires <i>w</i> exponentiations. The challenger knows <i>&Phi;</i>(<i>n</i>) which allows a more efficient computation by reducing the exponent <i>mod &Phi;</i>(<i>n</i>), so the challenger can execute VALUE() with 2 modular exponentiations. The challenger as a side-effect has a trapdoor in computing the cost-function as he can compute MINT() efficiently using the same algorithm.<br> 
We argue however that the added DDoS protection provided by non-parallelizable cost-functions is marginal: unless the server restricts the number of challenges it hands out to a recognizably unique client the DDoS attacker can farm out multiple challenges as easily as farm out a sub-divided single challenge, and consume resources on the server at the same rate as before. Further it is not that hard for a single client to masquerade as multiple clients to a server.<br> 
Consider also: the DDoS attacker has generally due to the nature of his method of commandeering nodes an equal number of network connected nodes at his disposal as processors. He can therefore in any case have each attack node directly participate in the normal protocol indistinguisably from any legitimate user. This attack strategy is also otherwise optimal anyway as the attack nodes will present a varied set of source addresses which will foil attempts at per-connection fairness throttling strategies and router based DDoS counter-measures based on volume of traffic across IP address ranges. Therefore for the natural attack node marshalling patterns non-parallelizable cost-functions offer limited added resistance.<br> 
As well as the arguments against the practical efficacy and value of non-parallelizable cost-functions, to date non-parallelizable cost functions have had orders of magnitude slower verification functions than non-parallelizable cost-functions. This is because the non-parallelizable cost-functions so far discussed in the literature are related to trap-door public key cryptography constructs which are inherently less efficient. It is an open question as to whether there exist non-parallelizable cost-functions based on symmetric-key (or public-key) constructs with verification functions of the same order of magnitude as those of symmetric-crypto based cost-functions.<br> 
While for the application of time-lock puzzles to cost-functions, a reduced public key size could be used to speed up the verification function, this approach introduces risk that the modulus will be factored with the result that the attacker gains a big advantage in minting tokens. (Note: factoring is itself a largely parallelizable computation.) 
To combat this the server should change the public parameters periodically. However in the particular case of the public parameters used by time-lock puzzles (which are the same as the RSA modulus used in RSA encryption), this operation is itself moderately expensive, so this operation would not be performed too frequently. It would probably not be wise to deploy software based on key sizes below 768 bits for this aplication, in addition it would help to change keys periodically, say every hour or so. (RSA modulii of 512 bits have recently been factored by a closed group as discussed in [11] and more recently have been demonstrated by Nicko van Someren et al to be factorizable using standard equipment in an office as reported in [12]; DDoS attackers are known be able to muster significant resources, probably easily exceeding those used in this demonstration.)<br> 
The time-lock puzzle cost-function also is necessarily trap-door as the server needs a private verification-key to allow it to efficiently verify tokens. The existance of a verification-key presents the added risk of key compromise allowing the attacker to by-pass the cost-function protection. (The interactive hashcash cost-function by comparison is trap-door-free, so there is no key which would allow an attacker a short-cut in computing tokens). In fact if the verification-key were compromised, it could be replaced, but this need adds complexity and administrative overhead as this event needs to be detected and manual intervention or some automated detection triggering key-replacement implemented.<br>  
The time-lock puzzle cost-function also will tend to have larger messages as there is a need to communicate planned and emergency re-keyed public parameters. For some applications, for example the syn-cookie and hashcash- cookie protocols, space is at a premium due to backwards compatibility and packet size constraints imposed by the network infrastructure.<br> 
So in summary we argue that non-parallelizable cost-functions are of questionable practical value in protecting against DDoS attacks, have more expensive verification functions, incur the risk of verification key compromise and attendant key management complexities, have larger messages, and are significantly more complex to implement. We therefore recommend instead the simpler hashcash protocol (or if the public-auditability and non-interactive options are not required Juels and Brainard's client-puzzles are roughly equivalent). 
 
<h3>7 Applications</h3> 
Apart from the initially proposed applications for hashcash of throttling DoS against remailer networks and detering email spam, since publication the following applications have been discussed, explored and in some cases implemented and deployed: 
<ul> 
<li> 
hashcash-cookies, a potential extension of the syn-cookie as discussed in section 4.2 for allowing more graceful service degradation in the face of connection-depletion attacks. 
</li> 
<li> 
interactive-hashcash as discussed in section 4 for DoS throttling and graceful service degradation under CPU overload attacks on security protocols with computationally expensive connection establishment phases. No deployment but the analogous client-puzzle system was implemented with TLS in [13] 
</li> 
<li> 
hashcash throttling of DoS publication floods in anonymous publication systems such as Freenet [14], Publius [15], Tangler [16], 
</li> 
<li> 
hashcash throttling of service requests in the cryptographic Self-certifying File System [17] 
</li> 
<li> 
hashcash throttling of USENET flooding via mail2news networks [18] 
</li> 
<li> 
hashcash as a minting mechanism for Wei Dai's b-money electronic cash proposal, an electronic cash scheme without a banking interface [19] 
</li> 
</ul> 
 
<h3>8 Cost-function classification scheme</h3> 
We list here a classification of characteristics of cost-functions. We use the following notation to denote the properties of a cost-function:<br> 
<br> 
<center> 
<img src='hashcash_fig8.png' width='500px'> 
</center> 
<br> 
Where <i>e</i> is the efficiency: value <i>e</i> = 1 means <i>efficiently-verifiable</i> - verifiable with cost comparable to or lower than the cost of verifying symmetric key constructs such as hashcash which consume just a single compression round of an iterative compression function based hash function such as SHA1 or MD5. Value <i>e</i> = &frac12; means <i>practically-verifiable</i> we mean less efficiently than efficienty-verifiable, but still efficient enough to be practical for some applications, for example the author considers the time-lock puzzle based cost-function with it's two modular exponentiations to fall into this category. Value <i>e</i> = 0 means <i>verifiable but impractical</i>, that the cost-function is verifiable but the verification function is impractically slow such that the existance of the cost-function serves only as a proof of concept to be improved upon for practical use.<br> 
And <i>&sigma;</i> is a characterization of the standard-deviation, value <i>&sigma;</i> = 0 means <i>fixed-cost</i>, <i>&sigma;</i> = &frac12; means <i>bounded probabilistic cost</i> and <i>&sigma;</i> = 1 means <i>unbounded probabilistic cost</i>. Note by <i>bounded probabilistic-cost</i> we mean usefully bounded - a bound in the work factor in excess of a work-factor that an otherwise functionally similar unbounded cost-function would only reach with negligible probability would not be useful.<br> 
And <i>i</i> denotes that the cost-function is <i>interactive</i>, and &#299; that the cost-function is <i>non-interactive</i>.<br> 
And <i>a</i> denotes that the cost-function is <i>publicly auditable</i>, #257; denotes that the cost-function is <i>not publicly auditable</i>, which means in practice that it is only verifiable by the service using a private key material. Note by <i>public-auditability</i> we mean <i>efficiently</i> publicly-auditable, and would not consider repeating the work of the token minter as adequate efficiency to classify.<br> 
And <i>t</i> denotes that the server has a <i>trapdoor</i> in computing the cost-function, conversely t&#773; denotes that server has no trapdoor in computing the cost-function.<br> 
And <i>p</i> denotes that the cost-function is <i>parallelizable</i>, <i>p&#773;</i> denotes that the cost-function is <i>non-parallelizable</i>.<br> 
<br> 
<img src='hashcash_fig9.png' width='500px'> 
<br> 
<h4>8.1 Open Problems</h4> 
<ul> 
<li> 
existance of <i>efficiently-verifiable non-interactive fixed-cost</i> cost-functions (<i>e</i> = 1, &sigma; = 0, i&#773; ) (and the related weaker problem: existance of same with probabilistic bounded-cost (<i>e</i> = 1, &sigma; = &frac12;, i&#773; )) 
</li> 
<li> 
existance of <i>efficiently-verifiable non-interactive non-parallelizable</i> cost-functions (<i>e</i> = 1, i&#773;, p&#773; ) (and the related weaker problem: existance of same in interactive setting (<i>e</i> = 1, i, p&#773; )) 
</li> 
<li> 
existance of <i>publicly-auditable non-interactive fixed-cost</i> cost-functions (<i>&sigma;</i> = 0, i&#773;, a) (and the related weaker problem: existance of same with bounded probabilistic-cost (<i>&sigma;</i> = &frac12;, i&#773;, a)) 
</li> 
</ul> 
 
<h3>References</h3> 
<div style='padding-left: 3em; text-indent: -3em;'> 
<p>[1] Adam Back. Hashcash, May 1997. Published at http://www.cypherspace.org/hashcash/.</p> 
<p>[2] Cynthia Dwork and Moni Naor. Pricing via processing or combatting junk mail. In Proceedings of Crypto, 1992. Also available as http://www.wisdom.weizmann.ac.il:81/Dienst/UI/2.0/Describe/ ncstrl.weizmann_il/CS95-20.</p> 
<p>[3] Ari Juels and John Brainard. Client puzzles: A cryptographic countermeasure against connection depletion attacks. In Network and Distributed System Security Symposium, 1999. Also available as http://www. rsasecurity.com/rsalabs/staff/bios/ajuels/publications/client-puzzles/.</p> 
<p>[4] Markus Jakobsson and Ari Juels. Proofs of work and bread pudding protocols. In Proceedings of the IFIP TC6 and TC11 Joint Working Conference on Communications and Multimedia Security (CMS '99), Leuven, Belgium, September 1999. Also available as http://citeseer.nj.nec.com/238810.html.</p> 
<p>[5] Dan Bernstein. Syn cookies. Published at http://cr.yp.to/syncookies.html.</p> 
<p>[6] Hal Finney. Personal communication, Mar 2002.</p> 
<p>[7] Thomas Boschloo. Personal communication, Mar 2002.</p> 
<p>[8] Andy Oram, editor. Peer-to-Peer: Harnessing the Power of Disruptive Technologies. O'Reilly and Associates, 2001. Chapter 16 also available as http://freehaven.net/doc/oreilly/ accountability-ch16.html.</p> 
<p>[9] Adam Back. Hashcash - amortizable publicly auditable cost functions. Early draft of paper, 2000.</p> 
<p>[10] Ronald L Rivest, Adi Shamir, and David A Wagner. Time-lock puzzles and timed-release crypto. Technical Report MIT/LCS/TR-684, 1996. Also available as http://theory.lcs.mit.edu/&tilde;rivest/ publications.html.</p> 
<p>[11] Herman te Riele. Security of e-commerce threatened by 512-bit number factorization. Published at http://www.cwi.nl/&tilde;kik/persb-UK.html, Aug 1999.</p> 
<p>[12] Dennis Fisher. Experts debate risks to crypto, Mar 2002. Also available as http://www.eweek.com/article/0,3658,s=720&a=24663,00.asp.</p> 
<p>[13] Drew Dean and Adam Stubblefield. Using cleint puzzles to protect tls. In Proceedings of the 10th USENIX Security Symposium, Aug 2001. Also available as http://www.cs.rice.edu/&tilde;astubble/papers.html.</p> 
<p>[14] Ian Clarke, Oskar Sandberg, Brandon Wiley, and Theodore Hong. Freenet: A distributed anonymous information storage and retrieval system. In Hannes Federrath, editor, Proceedings of the International Workshop on Design Issues in Anonymity and Unobservability. Springer, 2001. Also available as http://freenetproject.org/cgi-bin/twiki/view/Main/Papers.</p> 
<p>[15] Marc Waldman, Aviel D Rubin, and Lorrie Faith Cranor. Publius: A robust, tamper-evident, censorship- resistant web publishing system. In Proceedings of the 9th USENIX Security Symposium, Aug 2000. Also available as http://www.usenix.org/publications/library/proceedings/sec2000/waldman/waldman_html/v2.html.</p> 
<p>[16] Marc Waldman and David Mazieres. Tangler: A censorship resistant publishing system based on document entanglement. In Proceedings of the 8th ACM Conference on Computer and Communication Security, Nov 2001. Also available as http://www.cs.nyu.edu/&tilde;waldman/.</p> 
<p>[17] David Mazieres. Self-certifying File System. PhD thesis, Massachusetts Institute of Technology, May 2000. Also available as http://scs.cs.nyu.edu/&tilde;dm/.</p> 
<p>[18] Alex de Joode. Hashcash support at dizum mail2news gateway. Published at https://ssl.dizum.com/ hashcash/, 2002.</p> 
<p>[19] Wei Dai. b-money. Published at http://www.eskimo.com/&tilde;weidai/bmoney.txt, Nov 1998.</p> 
</div> 
</div>" 
 }, 
 { 
 "title": "Protocols for public key cryptosystems", 
 "subTitle": "R.C. Merkle, 1980", 
 "published": "Published in: Symposium on Security and Privacy, IEEE Computer Society, 1980", 
 "text": " 
<center> 
<h2>PROTOCOLS FOR PUBLIC KEY CRYPTOSYSTEMS</h2><br> 
<br> 
Ralph C. Merkle<br> 
ELXSi International<br> 
Sunnyvale, Ca.<br> 
</center> 
<br> 
<p><strong>Abstract</strong> New cryptographic protocols which take full advantage of the unique properties of public key cryptosystems are now evolving. Several protocols for public key distribution and for digital signatures are briefly compared with each other and with the conventional alternative. 
<h3>1. Introduction</h3> 
The special strengths of public key systems are briefly considered by examining cryptographic protocols for key distribution and digital signatures using both public key and conventional systems.<br> 
The reader is assumed to be familiar with the general ideas behind public key cryptosystems, as described in [1,10].<br> 
For many of the following examples we assume there are two communicants, called A and B, and an opponent E. A and B will attempt to send secret messages and sign contracts, while E will attempt to discover the keys, learn the secrets, and forge contracts. Sometimes, A will attempt to evade a contract he signed with B, or B will attempt to forge A's signature to a new contract.<br> 
A and B will need to apply one way functions to various arguments of various sizes, so we assume we have a one way function F which can be applied to arguments of any size and produce a fixed size output. For a more complete discussion of one way functions, see [2, 9, 13, 19]. 
<h3>2. Centralized Key Distribution</h3> 
Centralized key distribution using conventional encryption functions was the only reasonable method of handling key distribution in a multi-user network environment before the discovery of public key distribution methods. Only conventional encryption functions need be used, which presently offers a performance advantage. (Presently known public key systems are less efficient than conventional cryptographic systems. Whether or not this will continue is not now known. Discovery of new public key systems seems almost inevitable, and discovery of more efficient ones probable.)<br> 
In centralized key distribution, A, B, and all other system users somehow deposit a conventional cryptographic key with a central key distribution center. If A wishes to communicate with B, the key distribution center will send a common (session) key to A and B using the previously agreed on central keys. A and B can then communicate with no further assistance from the key distribution center.<br> 
This protocol is simple and requires only conventional encryption functions. Its use has been defended in the literature [17, 18, 20].<br> 
The major drawback of this protocol is its vulnerability to both centralized loss of security and centralized loss of function. Theft of the central keys, or bribery of personnel at the central site will compromise all users of the system.<br> 
Similarly, destruction of the central keys destroys the key distribution mechanism for all users.<br> 
The security and reliability of centralized key distribution can be increased by using two or more centers, each with its own keys [l]. Destruction or compromise of a single center will not affect the other centers.<br> 
Security can also be improved if all the user keys are encrypted with a master key by the center. The master key must still be stored securely (and suitable provision made for its backup), but the (encrypted) user keys can be stored anywhere. This approach is used by IBM [23].<br> 
This protocol does not fully solve the key distribution problem: some sort of key distribution method must be used between each user and the center to establish the original keys. This problem is nontrivial because no electronic communications can be used and inexpensive physical methods, e.g. , registered mail, offer only moderate security. The use of couriers is reasonably secure, although more expensive. 
<h3>3. Simple Public Key Distribution</h3> 
This is the most basic application of public key systems [1, 5, 6, 7, 8]. Its purpose is to allow A and B to agree on a common key k without any prior secret arrangements, even though E overhears all messages. A randomly computes enciphering and deciphering keys E<sub>A</sub> and D<sub>A</sub>, and sends E<sub>A</sub> to B (and E). B picks the random key, k, and transmits E<sub>A</sub>(k) to A (and E). A computes D<sub>A</sub> (E<sub>A</sub>(k)) = k. A then discards both E<sub>A</sub> and D<sub>A</sub>, and B discards E<sub>A</sub>. The key in future communications is k. It is used to encrypt all further messages using a conventional encryption function. Once A and B have finished talking, they both discard k. If they later resume the conversation the process is repeated to agree on a new key k'.<br> 
This protocol is very simple, and has a great deal to recommend it. First, no keys and no secret materials exist before A and B start communicating, and nothing is retained after they have finished. It is impossible for E to compromise any keys either before the conversation takes place, or after it is over, for the keys exist only during the conversation.<br> 
The disadvantage of this protocol is that E might actively interfere with the exchange of keys. Worse yet, E can force a known k on both A and B. 
<h3>4. Authenticated Public Key Distribution</h3> 
The now classic protocol [1] for secure and authenticated communications between A and B is: A and B generate E<sub>A</sub> and E<sub>B</sub> and make them public, while keeping D<sub>A</sub> and D<sub>B</sub> secret. The public enciphering keys of all users are entered in a public file, allowing easy and authenticated access to E<sub>X</sub> for any user, X.<br> 
If A and B wish to agree on a common key k, then each sends a (session) key to the other by encrypting it with the others public key. The two keys thus agreed on are combined and used to encrypt further messages.<br> 
At the end of this protocol, A and B have agreed on a common key, k, which is both secret and authenticated.<br> 
This protocol suffers from two weaknesses. First, entries in the public file might be altered. This can be dealt with both by good physical security, or by using new protocols (see sections 5 and 6) for authenticating the entries in the public file.<br> 
Second, secret deciphering keys can be lost. This problem must ultimately be solved by good physical security. 
<h3>5. Public Key Distribution with Certificates</h3> 
Kohnfelder [3] first suggested that entries in the public file be authenticated by having a Central Authority (CA) sign them with D<sub>CA</sub>. He called such signed entries <u>certificates</u>.<br> 
The protocol with certificates is the same as the authenticated protocol, except that A and B can now check the entries in the public file by checking each other's certificates. This protocol assures A and B that each has the other's public enciphering key, and not the public enciphering key of some imposter.<br> 
The security of this protocol rests on the assumptions that the secret deciphering keys of A, B, and CA have not been compromised; that A and B have correct copies of E<sub>CA</sub> (to check the signed certificates); and that CA has not issued a bad certificate, either deliberately because it was untrustworthy, or accidentally because it was tricked.<br> 
E<sub>CA</sub> can be published in newspapers and magazines, and sent over all available communication channels: blocking its correct reception would be very difficult.<br> 
If D<sub>CA</sub> is compromised, then it is no longer possible to authenticate the users of the system and their public enciphering keys. The certificates are now worthless because the (unauthorized) person who has learned D<sub>CA</sub> can produce false certificates at will. 
<h3>6. Public Key Distribution with Tree Authentication</h3> 
Key distribution with certificates was vulnerable to the criticism that D<sub>CA</sub> can be compromised, resulting in system wide loss of authentication. This problem can be solved by using tree authentication [13].<br> 
Again, this protocol attempts to authenticate entries in the public file. However, instead of signing each entry in the public file, this protocol applies a one way hash function, H, to the entire public file. Even though H is applied to the entire public file, the output of H is only 100 or 200 bits long. The (small) output of H will be called the root, R, of the public file.<br> 
If all users of the system know R, then all users can authenticate the correctness of the (whole) public file by computing R = H(public file). Any attempt to introduce changes into the public file will imply R &ne; H(altered public<br> 
file), an easily detected fact.<br> 
This method effectively eliminates the possibility of compromising D<sub>CA</sub> because no secret deciphering key exists.<br> 
Because the public file will be subjected to the harsh glare of public scrutiny, and because making alterations in the public file is effectively impossible after it has been published, a high degree of assurance that it is correct can be attained.<br> 
This method is impractical as stated. Fortunately, it is possible to selectively authenticate individual entries in the public file without having to know the whole public file by using Merkle's 'tree authentication,' [13].<br> 
The essence of tree authentication is to authenticate the entire public file by 'divide and conquer.' If we define <u>y</u> = public file = Y<sub>1</sub>, Y<sub>2</sub>, . . . Y<sub>n</sub>, (so the i<u>th</u> entry in the public file is denoted Y<sub>i</sub> and B's entry is Y<sub>B</sub>); we can define H(public file) = H(<u>Y</u>) as:<br> 
<br> 
H(<u>Y</u>) = F( H(first half of <u>Y</u>), H(second half of <u>Y</u>) )<br> 
<br> 
Where F is a one way function.<br> 
<br> 
If A wishes to confirm B's public enciphering key, then A need only know the first half of the public file, (which is where Y<sub>B</sub> appears) and H(second half of public file) which is only 100 bits long. A can compute H(public file) knowing only this information, and yet A only knew half the entries in the public file.<br> 
In a similar fashion, A does not really need to know all of the first half of the public file, for<br> 
<br> 
H(first half of public file) = F( H(first quarter of public file), H(second quarter of public file) )<br> 
<br> 
All A needs to know is the first quarter of the public file (which has Y<sub>B</sub>), and H(second quarter of public file).<br> 
By applying this concept recursively, A can confirm Y<sub>B</sub> in the public file knowing only R, log<sub>2</sub> n intermediate values, and Y<sub>B</sub> itself. The information needed to authenticate Y<sub>B</sub>, given that R has already been authenticated, lies along the path from R to Y<sub>B</sub> and will be called the authentication path.<br> 
These definitions are illustrated in figure 1, which shows the authentication path for Y<sub>5</sub>.<br><br> 
<center> 
<img src='protocols_fig1.png' width='350px'> 
<br> 
<i>Figure 1</i><br> 
</center> 
<br> 
For a more detailed discussion the reader is referred to [13].<br> 
<br> 
Using tree authentication, user A has an authentication path which can be used to authenticate user A's public enciphering key, provided only that R has already been authenticated. An 'authentication path' is a new form of certificate, with E<sub>CA</sub> replaced by R.<br> 
This protocol can only be compromised if: D<sub>A</sub> or D<sub>B</sub> is compromised, or if R is not correctly known by A or B, or if there is a false and misleading entry in the public file.<br> 
The latter two are easily detectable. If either A or B has the wrong R, they will be unable to complete the protocol with any other legitimate user who has the correct R, a fact that will be quickly detected.<br> 
Because the public file is both open to public scrutiny and unalterable, false or misleading entries can be rapidly detected. In practice, a few users concerned with correctness can verify that the public file satisfies some simple global properties, i.e., each user name appears once and once only in the entire public file; individual users can then verify that their own entry is correct, and need not bother examining the rest of the public file.<br> 
<br> 
The only practical method of compromising this protocol is to compromise D<sub>A</sub> or D<sub>B</sub>.A user's security is thus dependent on himself and no one else. 
<h3>7. Digital Signatures</h3> 
The use of public key cryptosystems to provide digital signatures was suggested by Diffie and Hellman [1]. Rivest, Shamir and Adleman [8] have suggested an attractive implementation. Signature techniques based on methods other than public key cryptosystems have been suggested by Lamport and Diffie [l, 24], Rabin [15], and Merkle [13].<br> 
Digital signatures, whether based on conventional encryption functions, on public key cryptosystems, on probabilistic computations, or on other techniques share several important properties in common. These common properties are best illustrated by the following now classic example.<br> 
A wishes to place a purchase order with his stock broker B. A, on the Riviera, cannot send a written order to B in New York in time. All that A can quickly send to B is information, i.e., a sequence of bits, but B is concerned that A may later disclaim the order. A must somehow generate a sequence of bits (a digital signature) which will convince B (and if need be a judge) that A authorized the order. It must be easy for B to validate the digital signature, but impossible for him (or anyone other than A) to generate it (to prevent charges that B was dabbling in the market illegally with A's money).<br> 
There are digital signature schemes which do not involve public key cryptosystems but it will be convenient notationally to let A sign message m by computing the signature, D<sub>A</sub>(m). Checking a signature will then be done by computing m = E<sub>A</sub>(D<sub>A</sub>(m)). If E<sub>A</sub>(D<sub>A</sub>(m)) produces an illegible message (random bits) then the signature is rejected as invalid. This notation is somewhat misleading because the actual method of generating and validating signatures can be very different from this model; it is retained because it is widely known and because we will not discuss the differences among different digital signature methods, only their common properties.<br> 
Digital signature protocols are naturally divided into three parts : a method of signing messages used by A, a method for authenticating a signature used by B, and a method for resolving disputes, used by the judge. It is important to note that two protocols that differ only in the method of resolving disputes <u>are different</u>. Failure to understand this point has led to confusion in the literature [17, 20].<br> 
We now turn to specific digital signature protocols. 
<h3>8. A Conventional Signature Protocol</h3> 
A conventional 'signature' protocol relies on the observation that if A and B trust some central authority CA, and if A and B have a secure method of communicating with CA, then A can 'sign' a message simply by sending it to CA and relying on CA to adjudicate disputes. This approach is defended by some [17]. This protocol is subject to the weaknesses of centralized key distribution (described earlier). 
<h3>9. The Basic Digital Signature Protocol</h3> 
The first public key based digital signature protocol [l], proceeded by having A sign message m by computing D<sub>A</sub>(m) and giving it to B as the signed message. B (or a judge) can compute E<sub>A</sub>(D<sub>A</sub>(m)) = m, thus confirming the correctness of the signed message. A is held responsible for a signed message if and only if it can be verified by applying A's public enciphering key to it.<br> 
This protocol can be criticized [16, 17, 20] on two grounds: First, the public file might have been tampered with. Methods of authenticating the public file, discussed previously under key distribution protocols, solve this problem.<br> 
A second criticism is that A has no recourse should his secret deciphering key be compromised and made public. Anyone can sign any message they desire with A's compromised D<sub>A</sub>, and A will be held responsible.<br> 
It seems clear that A will only agree to this digital signature protocol if he can provide very good physical security for D<sub>A</sub>. The loss to A if D<sub>A</sub> is compromised can be substantial.<br> 
A different method of solving this problem is to alter the dispute resolution protocol so that A is not held responsible for his signature if his secret deciphering key is compromised and made public.<br> 
The fact that altering the dispute resolution procedure creates a different protocol has not been fully appreciated, and the preceding two protocols have been confused with each other for this reason. Some criticism of 'the' public key digital signature protocol has actually been of this second protocol, and failed to consider the first protocol at all.<br> 
If we assume that A knows D<sub>A</sub>, then under the second protocol A can make D<sub>A</sub> public and effectively disavow the signed message. For this reason, some critics have argued that this protocol is inadequate.<br> 
If we assume that A does not know D<sub>A</sub>, then he is unable to disavow his signature under this protocol. It is easy to design a system in which this is the case.<br> 
The major difference between the second protocol and the first is in the division of risk: in the second protocol B will be left holding the bag if A's signing key is compromised. Clearly, B must be given assurances that this condition is unlikely before he will be willing to use this protocol. 
<h3>10. The Time-Stamp Protocol</h3> 
A protocol that would allow A to report loss or theft of D<sub>A</sub> and disclaim messages signed after the reported loss yet force A to acknowledge the validity of signatures made before the reported loss must involve the concept of time.<br> 
We introduce time into the following protocol by using time-keepers who can digitally time-stamp information given to them. We assume that both A and B have agreed on a set of acceptable time-keepers whose time-stamps will be accepted in dispute resolution.<br> 
If A can report that D<sub>A</sub> has been lost, then he must report this fact to some agent who will be responsible for answering queries about the current status of D<sub>A</sub>, i.e., has it been lost or not. For simplicity, we shall assume this role is played by the central authority, CA. CA will sign messages stating that A's secret deciphering key has not been compromised as of the current time. These signed messages will be called 'validity-checks.'<br> 
In the time stamp protocol, user A signs message m by computing D<sub>A</sub>(m) and sending it to B. B then has a timekeeper time stamp the message and obtains a validity-check from CA. If D<sub>A</sub> has already been reported lost B rejects the signature, otherwise he accepts.<br> 
In dispute resolution, the judge holds that a message has been validly signed if and only if it can be checked by applying A's public enciphering key AND it has been time-stamped prior to any reported loss of D<sub>A</sub>.<br> 
This protocol provides very good assurance to all parties that they have been dealt with fairly.<br> 
The major disadvantage of this protocol, as compared with the basic digital signature protocol, is the requirement that B obtain both a time-stamp and a validity-check, presumably in real time. These requirements force the use of a communications network, which both increases expense and decreases reliability.<br> 
If B is willing to obtain the time-stamp and the validity-check after the transaction has been completed, i.e., within a few days, an off-line system can be used. This modified protocol could be used by B either as a fail-soft protocol during communications outages, or as the standard protocol if communication costs are too high.<br> 
Off-line operation is cheaper and more reliable, but it exposes B to some risk: A might have recently reported the loss of DA<sub>A</sub> and B would not know about it. If physical security for secret deciphering keys is good, this risk should be minimal. 
<h3>11. Witnessed Digital Signatures</h3> 
If the value of a transaction is high enough, it might be desirable to have a witness physically confirm that A signed message m. The witness, W, would compute D<sub>W</sub> ('I, W, physically saw A agree to and sign message m.'). It would be necessary for A and B to agree in advance on acceptable witnesses.<br> 
The primary advantage of this protocol is that it reduces B's risk. The primary disadvantage is that it forces A to find a (physically present) witness to confirm the transaction. 
<h3>12. Digital Signature Applications Not Involving Dispute</h3> 
Not all applications of digital signatures involve contracts between two potentially disputing parties. Digital signatures are also an ideal method of broadcasting authenticated messages from a central source which must be confirmed by many separate recipients, or repeatedly confirmed by the same recipient at different times to insure that the message has not been modified.<br> 
One example of such an application is the distribution of network software to individual nodes of a communications network. It would be clearly undesirable for any node to start executing the wrong software. On the other hand, it is very desirable to send updates to the nodes over the network itself. The obvious solution is for updates to be digitally signed by an appropriate network administrator, and for the nodes to check the digital signature prior to executing them.<br> 
This example leads naturally to another application of digital signatures in operating system security. A major risk to the security of an operating system is the possibility that the system code that it is executing today is not the same that it was executing yesterday: someone might have put a trap door into the operating system that lets them do anything they please. To guard against this possibility, the operating system could refuse to execute any code in privileged mode unless that code had been properly signed. Carried to its logical conclusion, the operating system would check the digital signature of privileged programs each time they were loaded into central memory If this check were implemented in hardware, it would be impossible for any software changes to subvert it. The machine would be physically incapable of executing code in privileged mode unless that code was signed.<br> 
If privileged programs are digitally signed by the programmer who originally wrote them, as well as by various supervisory levels, and if the computer is physically unable to execute unsigned code in privileged mode, then it is possible to have complete assurance that the privileged programs running on the computer right now have not been modified since they were given there final checkout and signed by the programmer. Of course, this does not necessarily mean that the operating system is secure, but it does eliminate a major class or worries. 
<h3>13. Conclusions</h3> 
This paper has briefly described a number of cryptographic protocols. Certainly, these are not the only ones possible; however, they are valuable tools to the system designer: they illustrate what can be achieved and provide feasible solutions to problems of recurring interest.<br> 
Further constructive work in this area is very much needed. 
<h3>14. ACKNOWLEDGEMENTS</h3> 
It is a great pleasure for the author to acknowledge the pleasant and informative conversations he had with Dov Andelman, Whitfield Diffie, Martin Hellman, Raynold Kahn, Loren Kohnfelder, Frank Olken, and Justin Reyneri. 
<h3>15. BIBLIOGRAPHY</h3> 
<div style='padding-left: 1em; text-indent: -1em;'> 
<p>1. Diffie, W., and Hellman, M. New directions in cryptography. IEEE Trans. on Inform. IT-22, 6(Nov. 1976), 644-654.</p> 
<p>2. Evans A. , Kantrowitz, w., and Weiss, E. A user authentication system not requiring secrecy in the computer. Comm. ACM 17, 8(Aug. 1974), 437-442.</p> 
<p>3. Kohnfelder, L.M. Towards a practical public-key cryptosystem. MIT EE Bachelor's thesis.</p> 
<p>4. Lipton, S.M. , and Matyas, S.M. Making the digital signature legal--and safeguarded. Data Communications (Feb. 1978), 41-52.</p> 
<p>5. McEliece, R.J. A public-key cryptosystem based on algebraic coding theory. DSN Progress Report, JPL, (Jan. and Feb. 1978), 42-44.</p> 
<p>6. Merkle, R. Secure Communications over Insecure Channels. Comm. ACM 21, 4(Apr. 1978), 294-299.</p> 
<p>7. Merkle, R. , and Hellman, M. Hiding information and signatures in trapdoor knapsacks. IEEE Trans .on Inform. IT- 24, 5(Sept. 1978), 525-530.</p> 
<p>8. Rivest, R.L., Shamir, A. , and Adleman, L. A method for obtaining digital signatures and public-key cryptosystems. Comm. ACM 21, 2 (Feb. 1978), 120-126.</p> 
<p>9. Wilkes, M.V., Time-Sharing Computer Systems. Elsevier, New York, 1972.</p> 
<p>10. Diffie, W., and Hellman, M.E., Privacy and authentication: an introduction to cryptography, Proceedings of the IEEE Vol. 67, No. 3, Mar. 1979 pp. 397-427.</p> 
<p>11. Squires, J. Russ monitor of U.S. phones, Chicago Tribune pp. 123, June 25, 1975.</p> 
<p>12. Davis, R. Remedies sought to defeat Soviet eavesdropping on microwave links, Microwave Syst., vol. 8, no. 6, pp. 17-20, June 1978.</p> 
<p>13. Merkle, R.C. A certified digital signature, to appear, CACM.</p> 
<p>14. Kahn, D. The Codebreakers, New York: Macmillan. 1967.</p> 
<p>15. Rabin, M.O., Digitalized signatures, in Foundations of Secure Computation, ed. Demillo, R.A., et. al. pp. 155-166.</p> 
<p>16. Saltzer, J. On Digital Signatures, private communication.</p> 
<p>17, Popek G.J. and Kline, C.S. Encryption Protocols, Public Key Algorithms, and Digital Signatures in Computer Networks in Foundations of Secure Computation pp. 133-153.</p> 
<p>18. Needham R.M. and Schroeder, M.D. Using Encryption for Authentication in Large Networks of Computers. CACM 21,12 Dec. 1978 pp. 993-999.</p> 
<p>19. Merkle, R. Secrecy, authentication, and public key systems. Stanford Elec. Eng. Ph.D. Thesis, ISL SEL 79-017, 1979.</p> 
<p>20. Popek, G.J., and Kline, C.S. Encryption and Secure computer networks. Computing Surveys 11,4 Dec. 1979 pp. 331-356.</p> 
<p>21. Simmons, G.J. Symmetric and Asymmetric Encryption. Computing Surveys 11, 4 Dec. 1979 pp. 305-330.</p> 
<p>22. Lamport, L. Time, clocks, and the ordering of events in a distributed system. CACM 21, 7 Jul 1978 pp. 558-565.</p> 
<p>23. Ehrsam, W.F., Matyas, S.M. , Meyer, C.H., and Tuchman, W.L. A cryptographic key management scheme for implementing the data encryption standard. IBM Sys. Jour. 17, 2 1978 pp. 106-125.</p> 
<p>24. Lamport, L., Constructing digital signatures from a one way function. SRI Intl. CSL - 98</p> 
</div> 
" 
 }, 
 { 
 "title": "An introduction to probability theory and its applications", 
 "subTitle": "W. Feller, 1957", 
 "published": "Publised by John Wiley & Sons, 1957", 
 "text": "Sorry, but this book is not included in the app because it would have been too much work." 
 } 
]} 
